name: Build and pack py packages
on:
  workflow_call:
    inputs:
      deploy:
        required: false
        type: string
        default: 'false'
      release:
        required: false
        type: string
        default: 'false'
      run_black:
        required: false
        type: string
        default: 'false'
        description: When 'true' black is run stopping the pipeline if any files are not properly formatted
      skip_testing:
        required: false
        type: string
        default: 'false'
      package_paths:
        required: false
        type: string
        default: '["./"]'
      distributions:
        required: false
        type: string
        default: '["focal", "jammy", "noble"]'
      install_test:
        required: false
        type: string
        default: 'true'
      install_test_docker:
        required: false
        type: string
        default: 'false'
      install_test_zmq:
        required: false
        type: string
        default: 'false'
      prod_publish_repos:
        required: false
        type: string
        default: '["ppa-stable"]'
      prod_publish_pypi:
        required: false
        type: string
        default: 'pypi-edge'

    secrets:
      auto_commit_user:
        required: false # only when deploy true
      auto_commit_mail:
        required: false # only when deploy true
      auto_commit_password:
        required: false # only when deploy true
      registry_user:
        required: true
      registry_password:
        required: true
      nexus_publisher_user:
        required: true
      nexus_publisher_password:
        required: true
      gh_token:
        required: true
      sonar_token:
        required: true

jobs:
  RefreshSource:
    if: ${{ inputs.deploy == 'false' && inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    steps:
      - uses: docker://chinthakagodawita/autoupdate-action:v1
        continue-on-error: true
        env:
          GITHUB_TOKEN: '${{ secrets.auto_commit_password }}'
          MERGE_MSG: "Branch was auto-updated."

  StaticAnalysis:
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}

    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        # Disabling shallow clone is recommended for improving relevancy of reporting
        fetch-depth: 0
        submodules: recursive

    - name: Install build-requirements
      run: |
        if [ -f build-apt-requirements.txt ]; then
          apt update
          echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections
          apt install -y $(grep -vE "^\s*#" build-apt-requirements.txt  | tr "\n" " ")
        fi
        python3 -m pip install -r build-requirements.txt

    - name: Run Black
      if: ${{ inputs.run_black == 'true' }}
      run: |
        python3 -m black \
          --line-length 100 \
          --diff \
          --check \
          .

    - name: Python Linters
      # run linters isolated so no issues are masked from SonarCloud
      run: |
        python3 -m flake8 \
          --isolated \
          --exclude dist,.*\.egg-info,.git,__pycache__,.tox,venv \
          --max-complexity 10 \
          --max-line-length 100 \
          --exit-zero \
          --output-file flake8-report.txt

        # pylint seems to not have a way to ignore configuration files
        # so we need to provide it a dummy one
        touch dummy-pylint-config
        python3 -m pylint \
          --rcfile dummy-pylint-config \
          --ignore-patterns dist,.*\.egg-info,.git,__pycache__,.tox,venv \
          --max-line-length 100 \
          --exit-zero \
          --recursive y \
          --output pylint-report.txt \
        .

    - name: Store python Linters files
      uses: actions/upload-artifact@v4
      with:
        name: linting_reports
        path: "./*-report.txt"
        retention-days: 5

  Build:
    needs: [StaticAnalysis]
    strategy:
        matrix:
          pack_path: ${{ fromJSON(inputs.package_paths) }}
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    outputs:
      package_name: ${{ steps.vars.outputs.py_pkg_name }}
      package_version: ${{ steps.releasevars.outputs.py_pkg_version }}

    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        # Disabling shallow clone is recommended for improving relevancy of reporting
        fetch-depth: 0
        submodules: recursive

    - name: Install build-requirements
      run: python3 -m pip install -r build-requirements.txt

    - name: Create links for package ${{ matrix.pack_path }}
      run: |
        ln -f ${{ matrix.pack_path }}/debian/setup.py setup.py
        ln -sf ${{ matrix.pack_path }}/debian debian

    - name: Raise version locally
      if: ${{ inputs.deploy == 'true' }}
      run: bump2version build setup.py --no-tag --no-commit --allow-dirty

    - name: Find Package details
      id: vars
      run: |
        PACKAGE_VERSION=$(cat .bumpversion.cfg | sed s/' '/''/g | grep 'current_version=' | sed s/'current_version='/''/g)
        PACKAGE_NAME=$(cat setup.py | grep name | cut -d '"' -f2)

        echo "py_pkg_name=$PACKAGE_NAME" >> $GITHUB_OUTPUT
        echo "py_pkg_version=$PACKAGE_VERSION" >> $GITHUB_OUTPUT

    - name: Sync setup.py
      run: sed -i s/"$(cat setup.py | grep version=)"/"    version=\"${{ steps.vars.outputs.py_pkg_version }}\","/g setup.py

    - name: Enable 4 digit version
      id: releasevars
      run: |
        PACKAGE_RELEASE_VERSION=$(echo ${{ steps.vars.outputs.py_pkg_version }} | sed s/"-"/"."/g)
        sed -i s/"$(cat setup.py | grep version=)"/"$(cat setup.py | grep version= | sed s/"-"/"."/g)"/g setup.py

        echo "py_pkg_version=$PACKAGE_RELEASE_VERSION" >> $GITHUB_OUTPUT

    - name: Build
      run: python3 -m build -o dist/${{ matrix.pack_path }}

    - name: Archive binary
      uses: actions/upload-artifact@v4
      with:
        name: packages_${{ matrix.pack_path }}
        path: dist/${{ matrix.pack_path }}/*
        retention-days: 5

    - name: Remove hardlinks for package ${{ matrix.pack_path }}
      run: |
        rm -f setup.py
        rm -f debian

  Raise:
    needs: [Build]
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    outputs:
      package_version: ${{ steps.vars.outputs.py_pkg_version }}
      commit_id: ${{ steps.commit_id.outputs.commit_id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install build-requirements
        run: |
          git config --global --add safe.directory $(pwd)
          python3 -m pip install -r build-requirements.txt

      - name: Auto Raise version
        if: ${{ inputs.deploy == 'true' }}
        run: |
          bump2version build setup.py --no-tag --no-commit --allow-dirty

      - name: Find Package details
        id: vars
        run: |
          PACKAGE_VERSION=$(cat .bumpversion.cfg | sed s/' '/''/g | grep 'current_version=' | sed s/'current_version='/''/g)
          #echo ::set-output name=py_pkg_version::$PACKAGE_VERSION
          echo "py_pkg_version=$PACKAGE_VERSION" >> $GITHUB_OUTPUT

      - name: Push auto raise version
        if: ${{ inputs.deploy == 'true' }}
        run: |
          git config --global user.name ${{ secrets.auto_commit_user }}
          git config --global user.email ${{ secrets.auto_commit_mail }}
          git add .bumpversion.cfg
          git add **__version__.py || true
          git commit -m "[skip actions] Automatic Bump of build version"

      - name: Set branch output
        id: var_branch
        run: |
          echo "Branch name is: ${GITHUB_REF#refs/heads/}"
          #echo ::set-output name=branch::${GITHUB_REF#refs/heads/}
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT

      - name: Raise App version
        if: ${{ inputs.deploy == 'true' }}
        uses: CasperWA/push-protected@v2.16.0
        with:
          token: ${{ secrets.auto_commit_password }}
          branch: ${{ steps.var_branch.outputs.branch }}
          unprotect_reviews: true

      - name: Commit of version
        id: commit_id
        run: |
          commit_hash=$(git log --format="%H" -n 1)
          #echo ::set-output name=commit_id::$commit_hash
          echo "commit_id=$commit_hash" >> $GITHUB_OUTPUT

  PublishPypi:
    needs: [Raise]
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    strategy:
        matrix:
          pack_path: ${{ fromJSON(inputs.package_paths) }}
    steps:
      - name: Download a single artifact
        uses: actions/download-artifact@v4
        with:
          name: packages_${{ matrix.pack_path }}
          path: dist_${{ matrix.pack_path }}/

      - name: Publish package to TestPyPI Experimental
        uses: pypa/gh-action-pypi-publish@v1.11.0
        with:
          user: ${{ secrets.nexus_publisher_user }}
          password: ${{ secrets.nexus_publisher_password }}
          repository-url: https://artifacts.cloud.mov.ai/repository/pypi-experimental/
          packages-dir: dist_${{ matrix.pack_path }}/

      - name: Publish package to TestPyPI Testing
        if: ${{ inputs.deploy == 'true' }}
        uses: pypa/gh-action-pypi-publish@v1.11.0
        with:
          user: ${{ secrets.nexus_publisher_user }}
          password: ${{ secrets.nexus_publisher_password }}
          repository-url: https://artifacts.cloud.mov.ai/repository/pypi-integration/
          packages-dir: dist_${{ matrix.pack_path }}/

  Debian-Pack:
    if: ${{ inputs.release == 'false' }}
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.distributions) }}
    needs: [Raise]
    runs-on: ubuntu-20.04
    outputs:
      package_version: ${{ needs.Raise.outputs.package_version }}
      commit_id: ${{ needs.Raise.outputs.commit_id }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        ref: ${{ needs.Raise.outputs.commit_id }}
        submodules: recursive
    
    - name: Login to registry.cloud.mov.ai Registry
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.registry_user }}
        password: ${{ secrets.registry_password }}
        registry: registry.cloud.mov.ai

    - name: Raise & Deb Pack
      env:
        PACKAGE_VERSION: ${{ needs.Raise.outputs.package_version }}
      run: |
        make pack_${{ matrix.distro }}

    - name: Archive binary
      uses: actions/upload-artifact@v4
      with:
        name: deb_artifacts_${{ matrix.distro }}
        path: artifacts/${{ matrix.distro }}/*.deb
        retention-days: 5

  Debian-Test:
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.distributions) }}
      fail-fast: false
    needs: [Raise, Debian-Pack]
    if: ${{ inputs.release == 'false' && inputs.install_test == 'true' }}
    runs-on: ubuntu-${{ matrix.distro == 'focal' && '20.04' || matrix.distro == 'jammy' && '22.04' || matrix.distro == 'noble' && '24.04' }}
    timeout-minutes: 90
    steps:
      - name: Maximize build space
        uses: AdityaGarg8/remove-unwanted-software@v4.1
        with:
          remove-android: 'true'
          remove-dotnet: 'true'
          remove-codeql: 'true'
          remove-docker-images: 'true'
          remove-large-packages: 'true'
          verbose: 'true'

      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install test requirements
        run: |
          python3 -m venv test_venv
          source test_venv/bin/activate
          python3 -m pip install -r build-requirements.txt
          deactivate

      - name: Prereq Docker
        if: ${{ inputs.install_test_docker == 'true' }}
        run: |
          sudo apt update && sudo apt install -y curl
          curl -fsSL https://get.docker.com -o get-docker.sh
          sh get-docker.sh

      - name: Download deb artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: deb_artifacts_${{ matrix.distro }}
          path: artifacts
          merge-multiple: true

      - name: Install debian artifacts
        run: |
          sudo apt update
          cd artifacts/
          find ./ -name "*.deb" -not -name "*src*" -exec sudo apt install -y {} \;

      - name: Run tests
        if: ${{ inputs.skip_testing != 'true' }}
        run: |
          source test_venv/bin/activate
          if [ -f tox.ini ]; then
              # run tests and generates coverage.xml
              tox
          else
              # run tests
              python3 -m pytest tests/
          fi
          deactivate

      - name: Store tests reports for SonarCloud
        uses: actions/upload-artifact@v4
        with:
          name: coverage_report
          path: ./coverage.xml
        if: ${{ matrix.distro == 'focal' && inputs.skip_testing != 'true' }}

      - name: Store logs of journalctl
        shell: bash
        if: always()
        run: |
          mkdir -p logs
          journalctl -u movai-service > ./logs/movai-service-journal-${{ matrix.distro }}.log || true

      - name: Stash logs of journalctl
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debian_test_journal_${{ matrix.distro }}
          path: ./logs/*
          retention-days: 5

  SonarCloud:
    if: ${{ inputs.release == 'false' }}
    needs: [Debian-Test]
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        # Disabling shallow clone is recommended for improving relevancy of reporting
        fetch-depth: 0
        submodules: recursive

    - name: Install build-requirements
      run: |
        python3 -m pip install -r build-requirements.txt

    - name: Download coverage reports
      uses: actions/download-artifact@v4
      with:
        name: coverage_report
        path: ./
      if: ${{ inputs.skip_testing != 'true' }}

    - name: Download linting reports
      uses: actions/download-artifact@v4
      with:
        name: linting_reports
        path: ./

    - name: Create SonarCloud project and disable autoscan
      uses: MOV-AI/action-sonarcloud-proj-config@v1
      with:
        sonar_org: 'mov-ai'
        sonar_token: ${{ secrets.sonar_token }}

    - name: SonarCloud Scan and Quality Gate check
      uses: SonarSource/sonarcloud-github-action@v2.0.2
      if: ${{ inputs.skip_testing != 'true' }}
      env:
        GITHUB_TOKEN: ${{ github.token }}  # Needed to get PR information, if any
        SONAR_TOKEN: ${{ secrets.sonar_token }}
      with:
        projectBaseDir: ./
        args: >
          -Dsonar.organization=mov-ai
          -Dsonar.projectKey=${{ github.repository_owner }}_${{ github.event.repository.name }}
          -Dsonar.sources=.
          -Dsonar.scm.provider=git
          -Dsonar.qualitygate.wait=true
          -Dsonar.qualitygate.timeout=300
          -Dsonar.coverage.exclusions=tests/**
          -Dsonar.cpd.exclusions=tests/**
          -Dsonar.python.version=3
          -Dsonar.python.flake8.reportPaths=flake8-report.txt
          -Dsonar.python.pylint.reportPaths=pylint-report.txt

    - name: SonarCloud Scan and Quality Gate check (no coverage)
      uses: SonarSource/sonarcloud-github-action@v2.0.2
      if: ${{ inputs.skip_testing == 'true' }}
      env:
        GITHUB_TOKEN: ${{ github.token }}  # Needed to get PR information, if any
        SONAR_TOKEN: ${{ secrets.sonar_token }}
      with:
        projectBaseDir: ./
        args: >
          -Dsonar.organization=mov-ai
          -Dsonar.projectKey=${{ github.repository_owner }}_${{ github.event.repository.name }}
          -Dsonar.sources=.
          -Dsonar.scm.provider=git
          -Dsonar.qualitygate.wait=true
          -Dsonar.qualitygate.timeout=300
          -Dsonar.coverage.exclusions=tests/**
          -Dsonar.cpd.exclusions=tests/**
          -Dsonar.python.version=3
          -Dsonar.python.flake8.reportPaths=flake8-report.txt
          -Dsonar.python.pylint.reportPaths=pylint-report.txt
          -Dsonar.python.coverage.reportPaths=coverage.xml

    - name: Link to SonarCloud dashboard
      shell: bash
      run: |
        echo "Please check report here: https://sonarcloud.io/project/overview?id=${{ github.repository_owner }}_${{ github.event.repository.name }}"

  PublishDebian:
    needs: [Raise, Debian-Pack, Debian-Test, SonarCloud]
    if: ${{ inputs.deploy == 'true' }}
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.distributions) }}
      fail-fast: false
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Download deb artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: deb_artifacts_${{ matrix.distro }}
          path: artifacts
          merge-multiple: true

      - name: Publish to Nexus ppa-dev
        shell: bash
        run: |
            NEXUS_ENDPOINT="artifacts.cloud.mov.ai"
            NEXUS_REPO="ppa-devel-${{ matrix.distro }}"

            for file in artifacts/*.deb
            do
              RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
              -H "Content-Type: multipart/form-data" \
              --data-binary "@$file" \
              -w '%{http_code}' \
              "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  -H "Content-Type: multipart/form-data" \
                  --data-binary "@$file" \
                  -w '%{http_code}' \
                  "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Exiting"
                exit 1
              fi
            done

      - name: Publish to Nexus ppa-testing
        shell: bash
        run: |
            NEXUS_ENDPOINT="artifacts.cloud.mov.ai"
            NEXUS_REPO="ppa-testing-${{ matrix.distro }}"

            for file in artifacts/*.deb
            do
              RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
              -H "Content-Type: multipart/form-data" \
              --data-binary "@$file" \
              -w '%{http_code}' \
              "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  -H "Content-Type: multipart/form-data" \
                  --data-binary "@$file" \
                  -w '%{http_code}' \
                  "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Exiting"
                exit 1
              fi
            done

  Github-Release:
    needs: [Raise, Debian-Pack, Debian-Test, SonarCloud, PublishDebian]
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Download package artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: packages_*
          path: dist
          merge-multiple: true

      - name: Create Github Release
        if: ${{ inputs.deploy == 'true' }}
        shell: bash
        run: |
          title="Release of ${{ needs.Raise.outputs.package_version }}"
          git config --global --add safe.directory $(pwd)

          gh release create -p -t "$title" \
          -n "Release notes of version ${{ needs.Raise.outputs.package_version }}" \
          --target "${{ needs.Raise.outputs.commit_id }}" \
          --generate-notes \
           ${{ needs.Raise.outputs.package_version }}


          # add all files in the artifacts folder
          assets=()
          for asset in dist/*; do
            # do nothing if folder is empty
            if [[ $asset != "dist/*" ]]; then
              gh release upload ${{ needs.Debian-Pack.outputs.package_version }} $asset
            fi
          done
          for asset in artifacts/*; do
            # do nothing if folder is empty
            if [[ $asset != "artifacts/*" ]]; then
              gh release upload ${{ needs.Debian-Pack.outputs.package_version }} $asset
            fi
          done
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}
  
  Github-Release-Debian-Upload:
    needs: [Raise, Debian-Pack, Debian-Test, SonarCloud, PublishDebian, Github-Release]
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.distributions) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Download deb artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: deb_artifacts_${{ matrix.distro }}
          path: artifacts
          merge-multiple: true

      - name: Update Github Release
        if: ${{ inputs.deploy == 'true' }}
        shell: bash
        run: |
          git config --global --add safe.directory $(pwd)

          for asset in artifacts/*; do
            # do nothing if folder is empty
            if [[ $asset != "artifacts/*" ]]; then
              # Add sufix of distro to asset name
              asset_renamed=$(basename $asset .deb)_${{ matrix.distro }}.deb
              cp $asset $asset_renamed
              gh release upload ${{ needs.Debian-Pack.outputs.package_version }} $asset_renamed
            fi
          done
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

  ReleasePypi:
    if: ${{ inputs.release == 'true' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
  
      - name: Set tag output
        id: vars
        run: echo "tag=${GITHUB_REF#refs/*/}" >> $GITHUB_OUTPUT
  
      - name: Fetch artifact from github release
        run: |
          git config --global --add safe.directory $(pwd)
          mkdir dist artifacts
          cd dist
          gh release download ${{ steps.vars.outputs.tag}} -p *.whl
          gh release download ${{ steps.vars.outputs.tag}} -p *.tar.gz
          cd ../artifacts
          gh release download ${{ steps.vars.outputs.tag}} -p *.deb
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}
  
      - name: Archive binary
        uses: actions/upload-artifact@v4
        with:
          name: released_packages
          path: dist/*
          retention-days: 5
  
      - name: Archive binary
        uses: actions/upload-artifact@v4
        with:
          name: released_deb_artifacts
          path: artifacts/*.deb
          retention-days: 5

      - name: Publish package to prod PyPI
        uses: pypa/gh-action-pypi-publish@v1.11.0
        with:
          user: ${{ secrets.nexus_publisher_user }}
          password: ${{ secrets.nexus_publisher_password }}
          repository-url: https://artifacts.cloud.mov.ai/repository/${{ inputs.prod_publish_pypi }}/
      

  ReleasePpa:
    needs: [ReleasePypi]
    if: ${{ inputs.release == 'true' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    strategy:
      matrix:
        publish_repo: ${{ fromJSON(inputs.prod_publish_repos) }}
        distro: ${{ fromJSON(inputs.distributions) }}
      max-parallel: 1

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Download deb artifacts
      uses: actions/download-artifact@v4
      with:
        name: released_deb_artifacts
        path: artifacts/

    - name: Publish to Nexus
      shell: bash
      run: |
            NEXUS_REPO="${{ matrix.publish_repo }}-${{ matrix.distro }}"
            NEXUS_ENDPOINT="artifacts.cloud.mov.ai"

            ls -la artifacts

            for file in artifacts/*_${{ matrix.distro }}.deb
            do
              RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
              -H "Content-Type: multipart/form-data" \
              --data-binary "@$file" \
              -w '%{http_code}' \
              "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  -H "Content-Type: multipart/form-data" \
                  --data-binary "@$file" \
                  -w '%{http_code}' \
                  "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Exiting"
                exit 1
              fi

            done
