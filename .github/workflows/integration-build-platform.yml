name: Build Packer images
on:
  workflow_call:
    inputs:
      product_name:
        required: true
        type: string
      ros_distro:
        required: true
        type: string
      continue_on_mobtest_error:
        required: false
        type: boolean
        default: false
      fleet_ips:
        required: true
        type: string
      fleet_number_members:
        required: true
        type: number

    secrets:
      auto_commit_user:
        required: true
      auto_commit_mail:
        required: true
      auto_commit_pwd:
        required: true
      registry_user:
        required: true
      registry_password:
        required: true
      nexus_publisher_user:
        required: true
      nexus_publisher_password:
        required: true
      gh_token:
        required: true
      aws_key_id:
        required: true
      aws_secret_key_id:
        required: true
      slack_token_id:
        required: true
      ssh_pem_fleet_aws_vm:
        required: true
      proxmox_api_token_id:
        required: true
      proxmox_api_token_secret:
        required: true
      jira_username:
        required: true
      jira_password:
        required: true
      xray_clientid:
        required: true
      xray_secret:
        required: true
env:
  CI_INTEGRATION_SCRIPTS_VERSION: "2.1.0.19"
  MOBTEST_VERSION: "0.0.2.3"
  PACKAGE_DEPLOYER_VERSION: "1.0.0.21"
  GITHUB_API_USR: "OttoMation-Movai"
  AWS_ACCESS_KEY_ID: ${{ secrets.aws_key_id }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret_key_id }}
  AWS_DEFAULT_REGION: "us-east-1"
  REGISTRY: registry.cloud.mov.ai
  ENV: qa
  USERSPACE_FOLDER_PATH: userspace
  SIMULATION_ID: ci_simulation
  XRAY_CLIENTID: ${{ secrets.xray_clientid}}
  XRAY_SECRET: ${{ secrets.xray_secret}}
  JIRA_USERNAME: ${{ secrets.jira_username}}
  JIRA_PASSWORD: ${{ secrets.jira_password}}


jobs:
  Validate-boostrap-configs:
    runs-on: integration-pipeline
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Validate Manifest
        shell: bash
        run: |
          apt install -y yamllint
          yamllint product-manifest.yaml

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Bootstraping simulator metadata
        run: |
          git config --global --add safe.directory $(pwd)
          git fetch
          git checkout origin/${GITHUB_REF#refs/heads/} -- product.version
          cat product.version
          rm -rf simulator_artifacts ci_artifacts

          integration-pipeline generate_meta_simulator_artifacts \
                --manifest_platform_base_key product_components \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/}

          mkdir simulator_artifacts
          cp ci_artifacts/* ./simulator_artifacts

      - name: Bootstraping platform metadata
        run: |
          integration-pipeline generate_meta_artifacts \
                --manifest_platform_base_key product_components

      - name: Stash robot_configs
        uses: actions/upload-artifact@v2
        with:
          name: robot_configs
          path: "*.json*"

      - name: Stash sim_configs
        uses: actions/upload-artifact@v2
        with:
          name: sim_configs
          path: simulator_artifacts/*

      - name: raise
        run: |
          rm -rf simulator_artifacts ci_artifacts platform_configs
          mkdir platform_configs
          integration-pipeline raise
          cp product.version ./platform_configs/product.version
          cp product-manifest.yaml ./platform_configs/product-manifest.yaml

      - name: Stash raised_meta
        uses: actions/upload-artifact@v2
        with:
          name: raised_meta
          path: platform_configs/*

  Standalone-Validations:
    needs: [Validate-boostrap-configs]
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.ros_distro) }}
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo ::set-output name=ip::$ip

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v2
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA UI tests
        id: ui_tests_setup
        shell: bash
        run: |
          qa_key=ui_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/report_jira.txt /tmp/test_set.txt
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.jira_report --output_file /tmp/jira_report.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          report_jira=$(cat /tmp/jira_report.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir
          echo ::set-output name=target_dir::$tests_dir
          echo ::set-output name=test_set::$test_set
          echo ::set-output name=report_jira::$report_jira

      - name: Setup QA install tests
        id: install_tests_setup
        shell: bash
        run: |
          qa_key=install_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir
          echo ::set-output name=target_dir::$tests_dir


      - name: Setup QA API tests
        id: api_tests_setup
        shell: bash
        run: |
          qa_key=api_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir
          echo ::set-output name=target_dir::$tests_dir

      - name: Setup QA Flow tests
        id: flow_tests_setup
        shell: bash
        run: |
          qa_key=flow_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir
          echo ::set-output name=target_dir::$tests_dir
          echo ::set-output name=version::$tests_version

      - name: Feature File Validation
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          python3 testcasemanagement/testcase_importer.py --target "${{ steps.ui_tests_setup.outputs.test_set }}"
          python3 testcasemanagement/feature_file_processor.py --validate
          deactivate
          rm -R venv

      - name: Prepare QA Feature File Validation slack message
        if: always()
        id: pre_slack
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: \
          Feature File Validation Step FAILED and stopped Pipeline :rain_cloud: \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID} \
          Validate logs for cause troubleshooting."
          echo ::set-output name=msg_error::$MESSAGE_ERR

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02PB9A9F45"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Install tests
        id: install
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          set -x
          export PATH="$HOME/.local/bin:$PATH"

          #pushd $(pwd)/..
          #integration-pipeline get_json_value --file basic-standalone-noetic.json --key spawner.userspace --output_file robot_userspace
          #cat robot_userspace
          #mkdir -p $(cat robot_userspace | envsubst)

          #export USERSPACE_FOLDER_PATH="$(pwd)/$USERSPACE_FOLDER_PATH"
          #sudo chmod 777 -Rf $USERSPACE_FOLDER_PATH

          #popd

          python3 -m venv venv
          . venv/bin/activate
          pip install -r requirements.txt
          rm -rf results/*
          pytest tests/ -k 'AMR_installation_validator' --installPath="." --jsonConfigFilePath="../basic-standalone-noetic.json.ci"
          deactivate
          rm -R venv

          user=$(cat results/credentials.txt | awk -F: '{print $1}')
          pwd=$(cat results/credentials.txt | awk -F: '{print $2}')
          echo ::set-output name=movai_user::$user
          echo ::set-output name=movai_pwd::$pwd

      - name: Run mobtest
        continue-on-error: ${{ inputs.continue_on_mobtest_error }}
        shell: bash
        run: |
          container_id=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
          docker exec -t "$container_id" bash -c '
            set -e
            export PATH="$HOME/.local/bin:$PATH"
            python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple mobtest==${{ env.MOBTEST_VERSION }} --ignore-installed
            mobtest proj /opt/ros/${{ matrix.distro }}/share/
            '

      - name: API tests
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          echo "Movai user: ${{ steps.install.outputs.movai_user }}"
          echo "Movai password: ${{ steps.install.outputs.movai_pwd }}"
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          pytest src/tests \
              --base_url https://${{ steps.agent_info.outputs.ip }} \
              --username ${{ steps.install.outputs.movai_user }} \
              --password ${{ steps.install.outputs.movai_pwd }}
          deactivate
          rm -R venv

      - name: UI tests
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          echo "Movai user: ${{ steps.install.outputs.movai_user }}"
          echo "Movai password: ${{ steps.install.outputs.movai_pwd }}"

          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          if [ -n "${{ steps.ui_tests_setup.outputs.report_jira }}" ] ; then
            pytest -s \
              --hub_url http://172.22.0.105:4444 \
              --browser_name chrome \
              --browser_version 91.0 \
              --base_url https://${{ steps.agent_info.outputs.ip }}/ \
              --username ${{ steps.install.outputs.movai_user }} \
              --password ${{ steps.install.outputs.movai_pwd }} \
              --tb=short \
              --jira_report ${{ steps.ui_tests_setup.outputs.report_jira }}
          else
              pytest -s \
                --hub_url http://172.22.0.105:4444 \
                --browser_name chrome \
                --browser_version 91.0 \
                --base_url https://${{ steps.agent_info.outputs.ip }}/ \
                --username ${{ steps.install.outputs.movai_user }} \
                --password ${{ steps.install.outputs.movai_pwd }} \
                --tb=short
          fi
          deactivate
          rm -R venv

      - name: Flow tests
        working-directory: ${{ steps.flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          container_id=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
          docker exec -t "$container_id" bash -c '
            sudo apt update
            sudo apt install -y ros-noetic-movai-qa-node-params=${{ steps.flow_tests_setup.outputs.version }}
          '
          echo "Movai user: ${{ steps.install.outputs.movai_user }}"
          echo "Movai password: ${{ steps.install.outputs.movai_pwd }}"

          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          pytest -s \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            --tb=short
          deactivate
          rm -R venv

      - name: Collect Installed components
        shell: bash
        run: |
          mkdir -p artifacts

          used_images=($(docker images --format "{{.Repository}}:{{.Tag}}" | tr ' ' "\n"))
          for image in "${used_images[@]}"
          do
            image_short_name=$(grep -oP "(?<=/$ENV/).*?(?=:)" <<< "$image" || grep -oP "(?<=/devops/).*?(?=:)" <<< "$image" || true)
            if [[ "$image_short_name" =~ .*"backend".* || "$image_short_name" =~ .*"spawner".* || "$image_short_name" =~ .*"redis"*.* || "$image_short_name" =~ .*"health-node".* ]];
            then
              echo "scanning $image"
              container_ids=($(docker ps -q -f "ancestor=$image" | tr ' ' "\n"))
              for container_id in "${container_ids[@]}"
              do
                container_name=$(docker inspect --format="{{.Name}}" $container_id)
                docker exec -t "$container_id" bash -c '
                  set -e

                  sudo apt update || apt update
                  export PATH="$HOME/.local/bin:$PATH"
                  python3 -m pip install --upgrade pip || wget https://bootstrap.pypa.io/get-pip.py -O - | python3
                  python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple movai-package-deployer==${{ env.PACKAGE_DEPLOYER_VERSION }}
                  package-deployer scan
                  ls -la /tmp
                ' || true
                  docker cp $container_id:/tmp/deployable.dploy artifacts/$container_name-${{ matrix.distro }}-deployable.dploy
                  docker cp $container_id:/tmp/undeployable.dploy artifacts/$container_name-${{ matrix.distro }}-3rdParty.dploy
              done
            else
              echo "Skipping scan of $image"
            fi
          done
          export PATH="$HOME/.local/bin:$PATH"
          package-deployer scan
          cp /tmp/deployable.dploy artifacts/host-${{ matrix.distro }}-deployable.dploy
          cp /tmp/undeployable.dploy artifacts/host-${{ matrix.distro }}-3rdParty.dploy

      - name: Stash deploy_artifacts_${{ matrix.distro }}
        uses: actions/upload-artifact@v2
        with:
          name: deploy_artifacts_${{ matrix.distro }}
          path: artifacts/*.dploy

      - name: Stash QA artifacts
        if: always()
        shell: bash
        run: |

          mkdir qa_artifacts
          cp -r install/results/*.log ./qa_artifacts
          cp -r install/results/test_report_*.html ./qa_artifacts

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v2
        with:
          name: qa_artifacts
          path: qa_artifacts/*

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Fleet-Validations:
    needs: [Validate-boostrap-configs]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo ::set-output name=ip::$ip

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v2
        with:
          name: robot_configs
          path: .

      - name: Provision remote vms (AWS)
        if: ${{ false }}
        shell: bash
        run: |
          mkdir aws_artifacts
          python3 -m pip install awscli
          cd staging
          export PATH="$HOME/.local/bin:$PATH"
          export product="platform"
          export version="$PRODUCT_RELEASE_VERSION"
          ./ec2_provision.sh
          cp -vf infra_ids.txt ../aws_artifacts/

      - name: Stash ci_infra_artifacts (AWS)
        if: ${{ false }}
        uses: actions/upload-artifact@v2
        with:
          name: ci_infra_artifacts
          path: aws_artifacts/*

      - name: Install terraform
        shell: bash
        run: |
          wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
          sudo apt update && sudo apt install terraform -y

      - name: Setup terraform proxmox provisioner
        id: provision_infra_setup
        shell: bash
        run: |
          provision_infra_dir=provision_scripts
          provision_infra_version=0.0.1-19
          provision_infra_repo_name=devops-tf-proxmox-fleet

          rm -rf $provision_infra_dir
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline fetch_by_tag --repo $provision_infra_repo_name --version $provision_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $provision_infra_dir
          ls -la $provision_infra_dir
          echo ::set-output name=target_dir::"$provision_infra_dir/hosts/hel/"

      - name: Provision remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        shell: bash
        run: |
          terraform init
          terraform plan
          terraform apply -auto-approve
        env:
          TF_VAR_number_agents: ${{ inputs.fleet_number_members }}
          TF_VAR_proxmox_api_url: "https://hel.mov.ai:8006/api2/json"
          TF_VAR_proxmox_api_token_id: ${{ secrets.proxmox_api_token_id }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.proxmox_api_token_secret }}
          TF_VAR_provision_ssh_pem: ${{ secrets.ssh_pem_fleet_aws_vm }}
          TF_VAR_ip_list: ${{ inputs.fleet_ips }}

      - name: Apply ansible inventory
        shell: bash
        run: |
          cp ${{ steps.provision_infra_setup.outputs.target_dir }}/hosts staging/hosts
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file staging/hosts --key fleet.children.managers.hosts.manager.ansible_host --output_file ./staging/manager_private_ip.txt


      - name: Setup ansible installation
        id: ansible_install_setup
        shell: bash
        run: |
          install_key=ansible_deploy

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.name --output_file /tmp/repo_name.txt
          install_infra_dir=$(cat /tmp/target_dir.txt)
          install_infra_version=$(cat /tmp/version.txt)
          install_infra_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $install_infra_repo_name
          integration-pipeline fetch_by_tag --repo $install_infra_repo_name --version $install_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $install_infra_dir
          ls -la $install_infra_dir
          echo ::set-output name=target_dir::$install_infra_dir

      - name: Ansible install platform
        working-directory: ${{ steps.ansible_install_setup.outputs.target_dir }}
        shell: bash
        run: |
          echo "${{ secrets.ssh_pem_fleet_aws_vm }}" > ~/.ssh/aws_slave.pem
          sudo chmod 600 ~/.ssh/aws_slave.pem
          python3 -m venv ansible-venv
          source ansible-venv/bin/activate
          python3 -m pip install -r requirements.txt
          ansible-galaxy collection install -r requirements.yml
          ansible-playbook install.yml -i ../staging/hosts --key-file ~/.ssh/aws_slave.pem --extra-vars=@"$(pwd)/.."/product-manifest.yaml -e fleet_domain_dns="" -e "{\"proxycerts__remote_redis_servers_fqn\": [$(cat ../staging/manager_private_ip.txt)]}" --skip-tags "ufw,hardening"
          execution_status=$?
          deactivate
          exit $execution_status

      - name: Teardown remote vms (AWS)
        if: ${{ false }}
        shell: bash
        run: |
          echo "Deleting $(cat aws_artifacts/infra_ids.txt)"
          python3 -m pip install awscli
          export PATH="$HOME/.local/bin:$PATH"
          aws ec2 terminate-instances --instance-ids $(cat aws_artifacts/infra_ids.txt)
          echo "Deleting $(cat aws_artifacts/infra_ids.txt)"
          python3 -m pip install awscli
          export PATH="$HOME/.local/bin:$PATH"
          aws ec2 terminate-instances --instance-ids $(cat aws_artifacts/infra_ids.txt)

      - name: Teardown remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        if: always()
        shell: bash
        run: terraform destroy -auto-approve
        env:
          TF_VAR_number_agents: ${{ inputs.fleet_number_members }}
          TF_VAR_proxmox_api_url: "https://hel.mov.ai:8006/api2/json"
          TF_VAR_proxmox_api_token_id: ${{ secrets.proxmox_api_token_id }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.proxmox_api_token_secret }}
          TF_VAR_provision_ssh_pem: ${{ secrets.ssh_pem_fleet_aws_vm }}
          TF_VAR_ip_list: ${{ inputs.fleet_ips }}

  Build-Simulator:
    needs: [Validate-boostrap-configs]
    runs-on: integration-pipeline
    env:
      DISTRO: noetic
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo ::set-output name=ip::$ip

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash sim_configs
        uses: actions/download-artifact@v2
        with:
          name: sim_configs
          path: simulator_artifacts

      - name: Prepare Skip variables
        id: pre_simulator_build
        run: |
          if [ ! -f "simulator_artifacts/version" ]; then
            echo ::set-output name=skip_simulator_build::"true"
          else
            echo ::set-output name=skip_simulator_build::"false"
          fi

      - name: Lint docker image
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          wget https://github.com/hadolint/hadolint/releases/download/v2.9.3/hadolint-Linux-x86_64
          chmod +x hadolint-Linux-x86_64
          ./hadolint-Linux-x86_64 docker/$DISTRO/Dockerfile-simulator -t error

      - name: Download models
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline fetch_simulator_models \
                --manifest_platform_base_key product_components \
                --gh_api_user $GITHUB_API_USR \
                --gh_api_pwd ${{ secrets.auto_commit_pwd }} \
                --target_dir "./models"

      - name: Login to Private Registry
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.REGISTRY }}

      - name: Prepare docker build variables
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        id: pre_build
        run: |
          echo ::set-output name=image_name::$(cat simulator_artifacts/simulator_name.ci)
          echo ::set-output name=base_name::$(cat simulator_artifacts/simulator_base.ci)

      - name: Build with args and push:${{ inputs.deploy }}
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        uses: docker/build-push-action@v3
        with:
          context: .
          platforms: linux/amd64
          file: docker/${{ env.DISTRO }}/Dockerfile-simulator
          push: true
          tags: "${{ env.REGISTRY }}/qa/${{ steps.pre_build.outputs.image_name }}"
          pull: true
          build-args: |
            BASE_IMAGE=${{ steps.pre_build.outputs.base_name }}
            CI_SCRIPT_VERSION=${{ env.CI_INTEGRATION_SCRIPTS_VERSION }}

      - name: Collect Installed components
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          cd simulator_artifacts
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline publish_simulator_state_artifacts \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/}

      - name: pre-stash
        shell: bash
        run: |
          echo "$REGISTRY/qa/$(cat simulator_artifacts/simulator_name.ci)" > simulator.image.artifact

      - name: Stash deploy_simulator_artifacts
        uses: actions/upload-artifact@v2
        with:
          name: deploy_simulator_artifacts
          path: simulator.image.artifact

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  publish:
    needs: [Standalone-Validations, Fleet-Validations, Build-Simulator]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: unstash robot_configs
        uses: actions/download-artifact@v2
        with:
          name: robot_configs
          path: .

      - name: unstash raised_meta
        uses: actions/download-artifact@v2
        with:
          name: raised_meta
          path: platform_configs

      - name: unstash deploy_artifacts_noetic
        uses: actions/download-artifact@v2
        with:
          name: deploy_artifacts_noetic
          path: artifacts

      - name: unstash deploy_simulator_artifacts
        uses: actions/download-artifact@v2
        with:
          name: deploy_simulator_artifacts
          path: .

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: Publish and create release
        shell: bash
        run: |
          set -m
          set -e
          git config --global --add safe.directory $(pwd)
          git config --global user.name '${{ secrets.auto_commit_user }}'
          git config --global user.email '${{ secrets.auto_commit_mail }}'
          git config --global user.password ${{ secrets.auto_commit_pwd }}

          cp ./platform_configs/product.version product.version
          cp ./platform_configs/product-manifest.yaml product-manifest.yaml

          mkdir -p deployment_artifacts
          package-deployer join --dploy_workspace "$(pwd)/artifacts"
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_image_list_from_manifest --manifest_platform_base_key product_components --docker_registry $REGISTRY
          cp *.json deployment_artifacts
          cp artifacts/merged.dploy deployment_artifacts/deployable.dploy
          echo -e "$(cat ./artifacts/product.image.artifact)\n$(cat ./simulator.image.artifact)" > deployment_artifacts/product.image.artifact

          cp product.version deployment_artifacts
          cp product-manifest.yaml deployment_artifacts
          product_version=$(cat product.version)

          # danger zone. Everything will be deleted.
          mv product-manifest.yaml product-manifest.yaml.bck

          git restore product.version
          git restore product-manifest.yaml
          git pull
          echo "$product_version" > product.version
 
          git add product.version
          git commit -m "[skip actions] Automatic Raise"
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare raise variables
        id: pre_raise
        run: |
          echo ::set-output name=branch::${GITHUB_REF#refs/heads/}

      - name: Raise App version
        uses: CasperWA/push-protected@v2
        with:
          token: ${{ secrets.auto_commit_pwd }}
          branch: ${{ steps.pre_raise.outputs.branch }}
          unprotect_reviews: true

      - name: Github Publish
        shell: bash
        run: |
          commit_hash=$(git log --format="%H" -n 1)
          product_version=$(cat product.version)
          gh release create -p --generate-notes --target "$commit_hash" -t "${{ inputs.product_name }} $product_version" $product_version
          # add all files in the deployment_artifacts folder
          find deployment_artifacts -type f -exec gh release upload $product_version {} \;
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack
        run: |
          MESSAGE=":white_check_mark: CI: ${GITHUB_REPOSITORY} (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is stable :sunny: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo ::set-output name=msg::$MESSAGE
          echo ::set-output name=msg_error::$MESSAGE_ERR

      - name: Slack message success
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02U028NMB7"
          slack-message: ${{ steps.pre_slack.outputs.msg }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02U028NMB7"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}
