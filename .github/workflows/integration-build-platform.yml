name: Build and Validate Platform
on:
  workflow_call:
    inputs:
      product_name:
        required: true
        type: string
      ros_distro:
        required: true
        type: string
      debug_fleet_keep_alive:
        required: false
        type: boolean
      fleet_ips:
        required: true
        type: string
      fleet_number_members:
        required: true
        type: number

    secrets:
      auto_commit_user:
        required: true
      auto_commit_mail:
        required: true
      auto_commit_pwd:
        required: true
      registry_user:
        required: true
      registry_password:
        required: true
      nexus_publisher_user:
        required: true
      nexus_publisher_password:
        required: true
      gh_token:
        required: true
      aws_key_id:
        required: true
      aws_secret_key_id:
        required: true
      slack_token_id:
        required: true
      ssh_pem_fleet_aws_vm:
        required: true
      proxmox_ve_username:
        required: true
      proxmox_ve_password:
        required: true
      jira_username:
        required: true
      jira_password:
        required: true
      xray_clientid:
        required: true
      xray_secret:
        required: true
env:
  CI_INTEGRATION_SCRIPTS_VERSION: "2.1.0.23"
  MOBTEST_VERSION: "0.0.4.3"
  PACKAGE_DEPLOYER_VERSION: "1.0.0.25"
  GITHUB_API_USR: "OttoMation-Movai"
  AWS_ACCESS_KEY_ID: ${{ secrets.aws_key_id }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret_key_id }}
  AWS_DEFAULT_REGION: "us-east-1"
  REGISTRY: registry.cloud.mov.ai
  ENV: qa
  USERSPACE_FOLDER_PATH: userspace
  SIMULATION_ID: ci_simulation
  XRAY_CLIENTID: ${{ secrets.xray_clientid}}
  XRAY_SECRET: ${{ secrets.xray_secret}}
  JIRA_USERNAME: ${{ secrets.jira_username}}
  JIRA_PASSWORD: ${{ secrets.jira_password}}
  SLACK_CHANNEL: "C02U028NMB7" # rnd-platform
  # development slack channel
  #SLACK_CHANNEL: "C05K2KF1UP8"

jobs:
  Validate-boostrap-configs:
    runs-on: integration-pipeline
    container:
      image: registry.aws.cloud.mov.ai/qa/py-buildserver:v3.0.3
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    outputs:
      slack_thread_id: ${{ fromJson(steps.send-message.outputs.slack-result).response.message.ts }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate Manifest
        shell: bash
        run: |
          yamllint product-manifest.yaml

      - name: Install CI Scripts in container
        shell: bash
        run: |
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Bootstraping simulator metadata
        run: |
          git config --global --add safe.directory $(pwd)
          git fetch
          git checkout origin/${GITHUB_REF#refs/heads/} -- product.version
          cat product.version
          rm -rf simulator_artifacts ci_artifacts

          integration-pipeline generate_meta_simulator_artifacts \
                --manifest_platform_base_key product_components \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/}

          mkdir simulator_artifacts
          cp ci_artifacts/* ./simulator_artifacts

      - name: Bootstraping platform metadata
        run: |
          integration-pipeline generate_meta_artifacts \
                --manifest_platform_base_key product_components

      - name: Stash robot_configs
        uses: actions/upload-artifact@v4
        with:
          name: robot_configs
          path: "*.json*"
          retention-days: 5

      - name: Stash sim_configs
        uses: actions/upload-artifact@v4
        with:
          name: sim_configs
          path: simulator_artifacts/*
          retention-days: 5

      - name: raise
        run: |
          rm -rf simulator_artifacts ci_artifacts platform_configs
          mkdir platform_configs
          integration-pipeline raise
          cp product.version ./platform_configs/product.version
          cp product-manifest.yaml ./platform_configs/product-manifest.yaml

      - name: Prepare slack variables
        if: always()
        id: pre_slack
        run: |
          MESSAGE="CI: ${GITHUB_REPOSITORY} (${GITHUB_REF#refs/heads/}), build: $(cat product.version) (Attempt: #${{ github.run_attempt }}) is starting to be validated :construction: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT

      - name: Send Slack Message
        uses: archive/github-actions-slack@master
        id: send-message

        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack.outputs.msg }}

      - name: Stash raised_meta
        uses: actions/upload-artifact@v4
        with:
          name: raised_meta
          path: platform_configs/*
          retention-days: 5

  Standalone-Validations:
    runs-on: ubuntu-20.04
    needs: [Validate-boostrap-configs]
    outputs:
      slack_thread_id: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}
    steps:
      - name: Pass through
        run: echo "Pass"

  Validation-UI-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    outputs:
      slack_thread_id: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear --system-site-packages # needed for apt dependencies
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed
          python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA UI tests
        id: ui_tests_setup
        shell: bash
        env:
          qa_key: ui_tests
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/jira_report.txt /tmp/test_set.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.jira_report --output_file /tmp/jira_report.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key version --output_file /tmp/platform_version.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          jira_report=$(cat /tmp/jira_report.txt)
          test_set=$(cat /tmp/test_set.txt)
          platform_version=$(cat /tmp/platform_version.txt)

          rm -rf $tests_repo_name

          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "jira_report=${jira_report}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT
          echo "platform_version=${platform_version}" >> $GITHUB_OUTPUT
          deactivate

          # setup tests venv in a step that is always executed
          python3 -m venv "${tests_dir}"/test-venv --clear --system-site-packages
          . "${tests_dir}"/test-venv/bin/activate
          pip install -r "${tests_dir}"/requirements.txt
          deactivate

      - name: Feature File Validation
        id: feature_file_ui
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . test-venv/bin/activate
          xray download ${{ steps.ui_tests_setup.outputs.test_set }}
          xray compare ./tests/feature/
          deactivate

      - name: Prepare QA Feature File Validation slack message
        if: always()
        id: pre_slack
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: \
          ${{ github.job }} feature file validation: ${{ steps.feature_file_ui.outcome }} \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02PB9A9F45"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Install
        id: install
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

          rm -rf artifacts ; mkdir -p artifacts
          cp *.json artifacts/

          . .ci-venv/bin/activate
          CONFIG_FILE_NAME="basic-standalone-noetic.json"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version
          deactivate

          export PUBLIC_IP=$(hostname -I | awk '{print $1}')
          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME

          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT

      - name: Install dependencies in spawner
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on spawner
          if [ -f apt-requirements.txt ]; then
            ## get spawner container name
            CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
            ## get apt dependencies
            APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
            ## install
            docker exec -t "${CONTAINER_ID}" bash -c "
              sudo apt update
              sudo apt install -y ${APT_DEPS}
            "
          fi

      - name: UI tests
        timeout-minutes: 120
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . test-venv/bin/activate

          python3 -m pytest \
            -ra \
            --hub_url http://selenoid-ui.hel.mov.ai \
            --base_url https://${{ steps.agent_info.outputs.ip }}/ \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            --cucumberjson=./results.json

          deactivate

      - name: Create Xray test execution
        if: always()
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        run: |
          # create test execution
          if [ "${{ steps.ui_tests_setup.outputs.jira_report }}" == "True" ] ; then
            . test-venv/bin/activate
            xray create ./results.json --version "EE ${{ steps.ui_tests_setup.outputs.platform_version }}" --label UI_Automation
            deactivate
          fi

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark:${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          for container in backend spawner messager-server; do
             CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^${container}-.*")
             docker logs "${CONTAINER_ID}" &> "${container}.log" || true
          done || true

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

          # spawner (mobros firmware)
          journalctl -u movai-service -t mobros --since '1hour ago' &> spawner-firmware.log || true

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          UI_DIR: ${{ steps.ui_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log and *.zip might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${UI_DIR}"/*.log ./qa_artifacts || true
          cp -r "${UI_DIR}"/*.tar ./qa_artifacts || true
          cp -r "${UI_DIR}"/*.json ./qa_artifacts || true
          cp -r "${UI_DIR}"/*.html ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa_artifacts_ui_tests
          path: qa_artifacts/*
          retention-days: 5

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validation-Install-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear --system-site-packages # needed for apt dependencies
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed
          python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA install tests
        id: install_tests_setup
        shell: bash
        env:
          qa_key: install_tests
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/jira_report.txt /tmp/test_set.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.jira_report --output_file /tmp/jira_report.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key version --output_file /tmp/platform_version.txt
          platform_version=$(cat /tmp/platform_version.txt)

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          jira_report=$(cat /tmp/jira_report.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "jira_report=${jira_report}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT
          echo "platform_version=${platform_version}" >> $GITHUB_OUTPUT
          deactivate

          # setup tests venv in a step that is always executed
          python3 -m venv "${tests_dir}"/test-venv --clear --system-site-packages
          . "${tests_dir}"/test-venv/bin/activate
          pip install -r "${tests_dir}"/requirements.txt
          deactivate

      - name: Feature File Validation
        id: feature_file_install
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . test-venv/bin/activate
          python3 testcasemanagement/testcase_importer.py --target "${{ steps.install_tests_setup.outputs.test_set }}"
          python3 testcasemanagement/feature_file_processor.py --validate
          deactivate

      - name: Prepare QA Feature File Validation slack message
        if: always()
        id: pre_slack
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: \
          ${{ github.job }} feature file validation: ${{ steps.feature_file_install.outcome }} \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02PB9A9F45"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Install tests
        timeout-minutes: 45
        id: install
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . test-venv/bin/activate
          export PATH="$HOME/.local/bin:$PATH"
          rm -rf results/*

          if [ "${{ steps.install_tests_setup.outputs.jira_report }}" == "True" ] ; then
          python3 -m pytest tests/ \
              -ra \
              -k '${{ steps.install_tests_setup.outputs.test_set }}' \
              --installPath="." --jsonConfigFilePath="../basic-standalone-noetic.json.ci" \
              --jira_report
          else
          python3 -m pytest tests/ \
              -ra \
              -k '${{ steps.install_tests_setup.outputs.test_set }}' \
              --installPath="." --jsonConfigFilePath="../basic-standalone-noetic.json.ci"
          fi
          deactivate

          user=$(cat results/credentials.txt | awk -F: '{print $1}')
          pwd=$(cat results/credentials.txt | awk -F: '{print $2}')

          echo "movai_user=${user}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${pwd}" >> $GITHUB_OUTPUT

      - name: Run mobtest
        shell: bash
        run: |
          container_id=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
          docker exec -t "$container_id" bash -c '
            set -e
            export PATH="$HOME/.local/bin:$PATH"
            python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple mobtest==${{ env.MOBTEST_VERSION }} --ignore-installed
            mobtest proj /opt/ros/noetic/share/
            '

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          for container in backend spawner messager-server; do
             CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^${container}-.*")
             docker logs "${CONTAINER_ID}" &> "${container}.log" || true
          done || true

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

          # Spawner (mobros firmware)
          journalctl -u movai-service -t mobros --since '1hour ago' &> spawner-firmware.log || true

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          INSTALL_DIR: ${{ steps.install_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${INSTALL_DIR}"/*.log ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/*.tar ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/results/*.log ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/results/*.zip ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/results/test_report_*.html ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa_artifacts_install_tests
          path: qa_artifacts/*
          retention-days: 5

      - name: Collect Installed components
        shell: bash
        run: |
          mkdir -p artifacts

          used_images=($(docker images --format "{{.Repository}}:{{.Tag}}" | tr ' ' "\n"))
          for image in "${used_images[@]}"
          do
            image_short_name=$(grep -oP "(?<=/$ENV/).*?(?=:)" <<< "$image" || grep -oP "(?<=/devops/).*?(?=:)" <<< "$image" || true)
            if [[ "$image_short_name" =~ .*"backend".* || "$image_short_name" =~ .*"spawner".* || "$image_short_name" =~ .*"redis"*.* || "$image_short_name" =~ .*"health-node".* || "" =~ .*"message-server*.*" ]];
            then
              echo "scanning $image"
              container_ids=($(docker ps -q -f "ancestor=$image" | tr ' ' "\n"))
              for container_id in "${container_ids[@]}"
              do
                container_name=$(docker inspect --format="{{.Name}}" $container_id)
                docker exec -t "$container_id" bash -c '
                  set -e

                  sudo apt update || apt update
                  export PATH="$HOME/.local/bin:$PATH"
                  python3 -m pip install --upgrade pip || wget https://bootstrap.pypa.io/get-pip.py -O - | python3
                  python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple movai-package-deployer==${{ env.PACKAGE_DEPLOYER_VERSION }}
                  package-deployer scan
                  ls -la /tmp
                ' || true
                  docker cp $container_id:/tmp/deployable.dploy artifacts/$container_name-noetic-deployable.dploy
                  docker cp $container_id:/tmp/undeployable.dploy artifacts/$container_name-noetic-3rdParty.dploy
              done
            else
              echo "Skipping scan of $image"
            fi
          done
          . .ci-venv/bin/activate
          package-deployer scan
          deactivate
          cp /tmp/deployable.dploy artifacts/host-noetic-deployable.dploy
          cp /tmp/undeployable.dploy artifacts/host-noetic-3rdParty.dploy

      - name: Stash deploy_artifacts_noetic
        uses: actions/upload-artifact@v4
        with:
          name: deploy_artifacts_noetic
          path: artifacts/*.dploy
          retention-days: 5

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          INSTALL_DIR: ${{ steps.install_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validation-API-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed
          python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA API tests
        id: api_tests_setup
        shell: bash
        env:
          qa_key: api_tests
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          deactivate

          # setup tests venv in a step that is always executed
          python3 -m venv "${tests_dir}"/test-venv --clear --system-site-packages
          . "${tests_dir}"/test-venv/bin/activate
          pip install -r "${tests_dir}"/requirements.txt
          deactivate

      - name: Install
        id: install
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

          . .ci-venv/bin/activate
          mkdir -p artifacts
          cp *.json artifacts/
          CONFIG_FILE_NAME="basic-standalone-noetic.json"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version
          deactivate

          export PUBLIC_IP=$(hostname -I | awk '{print $1}')
          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT

      - name: API tests
        timeout-minutes: 30
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . test-venv/bin/activate

          python3 -m pytest src \
            --movai-ip ${{ steps.agent_info.outputs.ip }} \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            -m "not fleet"

          deactivate

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          for container in backend spawner messager-server; do
             CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^${container}-.*")
             docker logs "${CONTAINER_ID}" &> "${container}.log" || true
          done || true

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

          # spawner (mobros firmware)
          journalctl -u movai-service -t mobros --since '1hour ago' &> spawner-firmware.log || true

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          API_DIR: ${{ steps.api_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log and *.zip might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${API_DIR}"/*.log ./qa_artifacts || true
          cp -r "${API_DIR}"/*.tar ./qa_artifacts || true
          cp -r "${API_DIR}"/results/*.zip ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa_artifacts_api_tests
          path: qa_artifacts/*
          retention-days: 5

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validation-Flow-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed
          python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA Flow tests
        id: flow_tests_setup
        shell: bash
        env:
          qa_key: flow_tests
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/test_set.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "version=${tests_version}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT
          deactivate

          # setup tests venv in a step that is always executed
          python3 -m venv "${tests_dir}"/test-venv --clear --system-site-packages
          . "${tests_dir}"/test-venv/bin/activate
          pip install -r "${tests_dir}"/requirements.txt
          deactivate

      - name: Install
        id: install
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

          mkdir -p artifacts
          cp *.json artifacts/
          . .ci-venv/bin/activate
          CONFIG_FILE_NAME="basic-standalone-noetic.json"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version
          deactivate

          export PUBLIC_IP=$(hostname -I | awk '{print $1}')
          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT
          execution_status=$?
          exit $execution_status
          rm movai_service_version

      - name: Flow tests
        timeout-minutes: 30
        working-directory: ${{ steps.flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on spawner
          if [ -f apt-requirements.txt ]; then
            ## get spawner container name
            CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
            ## get apt dependencies
            APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
            ## install
            docker exec -t "${CONTAINER_ID}" bash -c "
              sudo apt update
              sudo apt install -y ${APT_DEPS}
            "
          fi

          # run tests
          . test-venv/bin/activate

          python3 -m pytest \
            -s \
            -ra \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            -m '${{ steps.flow_tests_setup.outputs.test_set }}' \
            --tb=short

          deactivate

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Standalone-Validations.outputs.slack_thread_id }}

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          for container in backend spawner messager-server; do
             CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^${container}-.*")
             docker logs "${CONTAINER_ID}" &> "${container}.log" || true
          done || true

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

          # spawner (mobros firmware)
          journalctl -u movai-service -t mobros --since '1hour ago' &> spawner-firmware.log || true

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          FLOW_DIR: ${{ steps.flow_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts, they might not exist
          mkdir -p qa_artifacts
          cp -r "${FLOW_DIR}"/*.log ./qa_artifacts || true
          cp -r "${FLOW_DIR}"/*.tar ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa_artifacts_flow_tests
          path: qa_artifacts/*
          retention-days: 5

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validations-Finish:
    needs: [Validation-UI-Tests, Validation-Install-Tests, Validation-API-Tests, Validation-Flow-Tests]
    runs-on: ubuntu-20.04
    outputs:
      slack_thread_id: ${{ needs.Validation-UI-Tests.outputs.slack_thread_id }}
    steps:
      - name: Pass through
        run: echo "Pass"

  Fleet-Validations:
    needs: [Validate-boostrap-configs]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: Setup infra environment configs
        id: infra_env_configs_setup
        shell: bash
        run: |
          env_configs_dir=infra_env_configs
          env_configs_version=0.0.1-2
          env_configs_repo_name=devops-tf-env-conf

          rm -rf $env_configs_dir
          . .ci-venv/bin/activate
          integration-pipeline fetch_by_tag --repo $env_configs_repo_name --version $env_configs_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $env_configs_dir
          ls -la $env_configs_dir
          echo "target_dir=${env_configs_dir}" >> $GITHUB_OUTPUT
          deactivate

      - name: Setup terraform proxmox provisioner
        id: provision_infra_setup
        shell: bash
        run: |
          provision_infra_dir=provision_scripts
          provision_infra_version=1.0.0-3
          provision_infra_repo_name=devops-tf-proxmox-bpg

          rm -rf $provision_infra_dir
          . .ci-venv/bin/activate
          integration-pipeline fetch_by_tag --repo $provision_infra_repo_name --version $provision_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $provision_infra_dir
          deactivate
          ls -la $provision_infra_dir
          echo "target_dir=${provision_infra_dir}" >> $GITHUB_OUTPUT

      - name: Define Instance names
        id: infra_names
        shell: bash
        run: |
          branch=$(echo ${GITHUB_REF#refs/heads/} | sed "s;\.;-;g" )

          local_manager_prefix="ip-$branch-manager"
          local_worker_prefix="ip-$branch-worker"
          echo "$local_manager_prefix"
          echo "$local_worker_prefix"
          total_resources=${{ inputs.fleet_number_members }}
          ((total_resources+=1))

          echo "manager_prefix=${local_manager_prefix}" >> $GITHUB_OUTPUT
          echo "worker_prefix=${local_worker_prefix}" >> $GITHUB_OUTPUT
          echo "total_resources=${total_resources}" >> $GITHUB_OUTPUT

      - name: Provision remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        shell: bash
        run: |
          multiply_node=$(printf '"hel",%.0s' {1..${{ steps.infra_names.outputs.total_resources }}})
          node_list_str=${multiply_node::-1}

          var_file_arg='-var-file=../${{ steps.infra_env_configs_setup.outputs.target_dir }}/hel/hel_fleet_test.tfvars'

          echo "proxmox_host_list=[$node_list_str]">>input.tfvars
          echo "fleet_peer_nr=${{ inputs.fleet_number_members }}">>input.tfvars
          echo 'fleet_password="n/a"'>>input.tfvars
          echo 'fleet_manager_name="${{ steps.infra_names.outputs.manager_prefix }}"'>>input.tfvars
          echo 'fleet_peer_name_prefix="${{ steps.infra_names.outputs.worker_prefix }}"'>>input.tfvars
          echo 'ip_list=${{ inputs.fleet_ips }}'>>input.tfvars
          echo 'proxmox_ve_username="${{ secrets.proxmox_ve_username }}"'>>input.tfvars
          echo 'proxmox_ve_password="${{ secrets.proxmox_ve_password }}"'>>input.tfvars
          echo "\n">>input

          echo "File args: $var_file_arg"
          echo "Input File args: $(cat input.tfvars)"
          terraform init -backend-config="key=hel-fleet-${{ steps.infra_names.outputs.manager_prefix }}.tfstate"
          terraform apply -auto-approve $var_file_arg -var-file=input.tfvars
          terraform refresh $var_file_arg -var-file=input.tfvars

      - name: Prepare Devops provisioning slack message
        if: always()
        id: pre_slack_infra
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is being impacted by an infrastructural issue. \
          Provisioning of fleet infrastructure failed. Please take a look! \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "G0102LEV1CL"
          slack-message: ${{ steps.pre_slack_infra.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Apply ansible inventory
        shell: bash
        run: |
          . .ci-venv/bin/activate
          cp ${{ steps.provision_infra_setup.outputs.target_dir }}/provisioned_inventory.yml staging/provisioned_inventory.yml
          cat staging/provisioned_inventory.yml
          integration-pipeline get_yml_value --file staging/provisioned_inventory.yml --key fleet.children.managers.hosts.manager.ansible_host --output_file ./staging/manager_private_ip.txt
          deactivate

      - name: Setup ansible installation
        id: ansible_install_setup
        shell: bash
        env:
          install_key: ansible_deploy
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.name --output_file /tmp/repo_name.txt
          install_infra_dir=$(cat /tmp/target_dir.txt)
          install_infra_version=$(cat /tmp/version.txt)
          install_infra_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $install_infra_repo_name
          integration-pipeline fetch_by_tag --repo $install_infra_repo_name --version $install_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $install_infra_dir
          ls -la $install_infra_dir
          echo "target_dir=${install_infra_dir}" >> $GITHUB_OUTPUT
          deactivate

      - name: Ansible install platform
        id: ansible_install_platform
        working-directory: ${{ steps.ansible_install_setup.outputs.target_dir }}
        shell: bash
        run: |
          echo "${{ secrets.ssh_pem_fleet_aws_vm }}" > ~/.ssh/aws_slave.pem
          sudo chmod 600 ~/.ssh/aws_slave.pem
          while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 ; do echo Waiting for other software managers to finish... ; sleep 5;done
          python3.9 -m venv ansible-venv
          source ansible-venv/bin/activate
          python3 -m pip install -r requirements.txt
          ansible-galaxy install -r requirements.yml --timeout 120

          stripped_ips=$(echo ${{ inputs.fleet_ips }} | sed "s;\[;;g" | sed "s;];;g" | sed "s; ;;g")
          touch ~/.ssh/known_hosts
          sudo chmod 600 ~/.ssh/known_hosts
          IFS=',' read -r -a stripped_ips_arr <<< $stripped_ips

          manager_ip=${stripped_ips_arr[0]}
          echo "manager_ip=${manager_ip}" | tee >> $GITHUB_OUTPUT

          for ip in "${stripped_ips_arr[@]}"
          do
            if [[ $ip == *"/"* ]]; then
              ip=${ip%/*}
            fi
            ssh-keygen -f ~/.ssh/known_hosts -R $ip
            ssh-keyscan -H $ip >> ~/.ssh/known_hosts
          done

          # Ensure cloud init is done on all the hosts
          members=("manager")
          for i in $(seq 0 $(( ${{ inputs.fleet_number_members}} - 1 ))); do
            members+=("member$i")
          done

          for fleet_host in ${members[@]}; do
            ansible $fleet_host -i ../staging/provisioned_inventory.yml --key-file ~/.ssh/aws_slave.pem -m shell -a 'cloud-init status --wait'
          done

          ansible-playbook install.yml \
            -i ../staging/provisioned_inventory.yml \
            --key-file ~/.ssh/aws_slave.pem \
            --extra-vars=@"$(pwd)/.."/product-manifest.yaml \
            -e fleet_domain_dns="" \
            -e "{\"proxycerts__remote_redis_servers_fqn\": [$(cat ../staging/manager_private_ip.txt)]}" \
            -e '{"fleet_extra_hosts": ["172.22.0.106    registry.hel.mov.ai traefik"]}' \
            --skip-tags "validate,ufw,hardening"
          execution_status=$?
          deactivate
          exit $execution_status

      - name: Setup QA API tests
        id: api_tests_setup
        shell: bash
        env:
          qa_key: api_tests
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          deactivate

          # setup tests venv in a step that is always executed
          python3 -m venv "${tests_dir}"/test-venv --clear --system-site-packages
          . "${tests_dir}"/test-venv/bin/activate
          pip install -r "${tests_dir}"/requirements.txt
          deactivate

      - name: API tests
        timeout-minutes: 30
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . test-venv/bin/activate
          echo "Skip tests since they were never planned to run in this manner"
          deactivate

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          for container in backend spawner messager-server; do
             CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^${container}-.*")
             docker logs "${CONTAINER_ID}" &> "${container}.log" || true
          done || true

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}

      - name: Collect Fleet QA artifacts
        working-directory: ${{ steps.ansible_install_setup.outputs.target_dir }}
        if: always()
        shell: bash
        env:
          API_DIR: ${{ steps.api_tests_setup.outputs.target_dir }}
        run: |
          rm -rf fleet_qa_artifacts
          mkdir -p fleet_qa_artifacts/install
          source ansible-venv/bin/activate
          # install fleet_tests artifacts
          for fleet_host in "manager" "member0" "member1"; do
            ansible $fleet_host -i ../staging/provisioned_inventory.yml --key-file ~/.ssh/aws_slave.pem -m shell -a 'journalctl -u movai-service --since "1hour ago"' > fleet_qa_artifacts/install/$fleet_host.log || true

            echo "From $fleet_host:"
            ansible $fleet_host -i ../staging/provisioned_inventory.yml --key-file ~/.ssh/aws_slave.pem -m shell -a 'docker ps -a' > fleet_qa_artifacts/install/$fleet_host-docker_ps.log || true
            echo "$(tail -n +2 fleet_qa_artifacts/install/$fleet_host-docker_ps.log )"

            ansible $fleet_host -i ../staging/provisioned_inventory.yml --key-file ~/.ssh/aws_slave.pem -m shell -a 'journalctl -u docker --boot --lines=all' > fleet_qa_artifacts/install/$fleet_host-all-docker.log || true
          done

          deactivate

          # qa api tests artifacts
          # *.log and *.zip might not exist if the test fails early
          mkdir -p fleet_qa_artifacts/api
          cp -r "${API_DIR}"/*.log fleet_qa_artifacts/api || true
          cp -r "${API_DIR}"/*.tar fleet_qa_artifacts/api || true
          cp -r "${API_DIR}"/results/*.zip fleet_qa_artifacts/api || true

      - name: Stash Fleet QA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fleet_qa_artifacts
          path: ${{ steps.ansible_install_setup.outputs.target_dir }}/fleet_qa_artifacts/*
          retention-days: 5

      - name: Teardown remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        if: ${{ ( !inputs.debug_fleet_keep_alive && success() ) || cancelled() || ( !inputs.debug_fleet_keep_alive && failure() ) }}
        shell: bash
        run: |
          attempts=3
          count=0
          while [ $count -lt $attempts ]; do
            var_file_arg='-var-file=../${{ steps.infra_env_configs_setup.outputs.target_dir }}/hel/hel_fleet_test.tfvars'
            terraform destroy -auto-approve $var_file_arg -var-file=input.tfvars 
            exit_status=$?
            if [ $exit_status -eq 0 ]; then
              break
            elif [ $exit_status -eq 1 ]; then
              ((count++))
              echo "Retrying Terraform destroy (attempt $count)..."
            else
                  echo "Terraform destroy failed with exit status ${exit_status:-unknown}. Exiting..."
                  exit ${exit_status:-1}
            fi
          done

  Build-Simulator:
    needs: [Validate-boostrap-configs]
    runs-on: integration-pipeline
    env:
      DISTRO: noetic
    outputs:
      slack_thread_id: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}

    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash sim_configs
        uses: actions/download-artifact@v4
        with:
          name: sim_configs
          path: simulator_artifacts

      - name: Prepare Skip variables
        id: pre_simulator_build
        run: |
          if [ ! -f "simulator_artifacts/version" ]; then
            echo "skip_simulator_build=true" >> $GITHUB_OUTPUT
          else
            echo "skip_simulator_build=false" >> $GITHUB_OUTPUT
          fi

      - name: Lint docker image
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          hadolint docker/$DISTRO/Dockerfile-simulator -t error

      - name: Download models
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          . .ci-venv/bin/activate
          integration-pipeline fetch_simulator_models \
                --manifest_platform_base_key product_components \
                --gh_api_user $GITHUB_API_USR \
                --gh_api_pwd ${{ secrets.auto_commit_pwd }} \
                --target_dir "./models"
          deactivate
          if [ ! -d ./models ]; then mkdir -p ./models; fi

      - name: Login to Private Registry
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.REGISTRY }}

      - name: Prepare docker build variables
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        id: pre_build
        run: |
          echo "image_name=$(cat simulator_artifacts/simulator_name.ci)" >> $GITHUB_OUTPUT
          echo "base_name=$(cat simulator_artifacts/simulator_base.ci)" >> $GITHUB_OUTPUT

      - name: Build with args and push
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        uses: docker/build-push-action@v3
        with:
          context: .
          platforms: linux/amd64
          file: docker/${{ env.DISTRO }}/Dockerfile-simulator
          push: true
          tags: "${{ env.REGISTRY }}/qa/${{ steps.pre_build.outputs.image_name }}"
          pull: true
          build-args: |
            BASE_IMAGE=${{ steps.pre_build.outputs.base_name }}
            CI_SCRIPT_VERSION=${{ env.CI_INTEGRATION_SCRIPTS_VERSION }}

      - name: Collect Installed components
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          . .ci-venv/bin/activate
          cd simulator_artifacts
          integration-pipeline publish_simulator_state_artifacts \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/}
          deactivate

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}

      - name: pre-stash
        shell: bash
        run: |
          echo "$REGISTRY/qa/$(cat simulator_artifacts/simulator_name.ci)" > simulator.image.artifact

      - name: Stash deploy_simulator_artifacts
        uses: actions/upload-artifact@v4
        with:
          name: deploy_simulator_artifacts
          path: simulator.image.artifact
          retention-days: 5

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Simulator-Validations:
    needs: [Build-Simulator]
    runs-on: integration-pipeline
    steps:
      - uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        run: |
          echo "public ip: $(curl ipinfo.io/ip)"
          echo "private ip: $(hostname -I | awk '{print $1}')"

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear --system-site-packages
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed
          python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash raised_meta
        uses: actions/download-artifact@v4
        with:
          name: raised_meta
          path: .

      - name: unstash sim_configs
        uses: actions/download-artifact@v4
        with:
          name: sim_configs
          path: simulator_artifacts

      - name: unstash robot_jsons_noetic
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: Login to Private Registry
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.REGISTRY }}

      - name: Setup QA Flow tests
        id: sim_flow_tests_setup
        shell: bash
        env:
          qa_key: flow_tests
        run: |
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/test_set.txt
          . .ci-venv/bin/activate
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "version=${tests_version}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT
          deactivate

          # setup tests venv in a step that is always executed
          python3 -m venv "${tests_dir}"/test-venv --clear --system-site-packages
          . "${tests_dir}"/test-venv/bin/activate
          python3 -m pip install -r "${tests_dir}"/requirements.txt
          deactivate

      - name: Installation
        id: install
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

          mkdir -p artifacts
          cp *.json artifacts/

          CONFIG_FILE_NAME="basic-standalone-ignition-noetic.json"
          mkdir -p userspace/

          export USERSPACE_FOLDER_PATH="$(pwd)/userspace"
          export PUBLIC_IP=$(hostname -I | awk '{print $1}')
          . .ci-venv/bin/activate
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version
          deactivate

          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT
        env:
          DISPLAY: ":0"
          SIMULATION_ID: "CI"

      - name: Simulator tests
        timeout-minutes: 30
        working-directory: ${{ steps.sim_flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on spawner
          ## get spawner container name
          CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
          ## get apt dependencies
          APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
          ## install
          docker exec -t "${CONTAINER_ID}" bash -c "
            sudo apt update
            sudo apt install -y ${APT_DEPS}
          "

          # run tests
          . test-venv/bin/activate

          python3 -m pytest \
            -s \
            -ra \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            -m 'simulator' \
            --tb=short

          deactivate

      - name: Get current job id
        if: always()
        shell: bash
        id: job_info
        run: |
          job_id=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | .[0].id')
          job_html_url=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id}}/attempts/${{ github.run_attempt }}/jobs | jq -r '.jobs | map(select(.name | contains("${{ github.job }}"))) | .[0].html_url')
          echo "$job_id"
          echo "$job_html_url"
          echo "job_url=$job_html_url" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack_result
        run: |
          MESSAGE=":white_check_mark: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job passed"
          MESSAGE_ERR=":x: ${{ github.job }} (Attempt: #${{ github.run_attempt }}) job failed"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}\n  Details: ${{ steps.job_info.outputs.job_url }}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: archive/github-actions-slack@master
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg }}
          slack-optional-thread_ts: ${{ needs.Build-Simulator.outputs.slack_thread_id }}

      - name: Slack message failure
        uses: archive/github-actions-slack@master
        if: failure()
        with:
          slack-function: send-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-text: ${{ steps.pre_slack_result.outputs.msg_error }}
          slack-optional-thread_ts: ${{ needs.Build-Simulator.outputs.slack_thread_id }}

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.sim_flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          for container in backend spawner messager-server; do
             CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^${container}-.*")
             docker logs "${CONTAINER_ID}" &> "${container}.log" || true
          done || true

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

          # spawner (mobros firmware)
          journalctl -u movai-service -t mobros --since '1hour ago' &> spawner-firmware.log || true

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          SIM_DIR: ${{ steps.sim_flow_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${SIM_DIR}"/*.log ./qa_artifacts || true
          cp -r "${SIM_DIR}"/*.tar ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa_artifacts_simulator_tests
          path: qa_artifacts/*
          retention-days: 5

      - name: Collect Installed components
        shell: bash
        run: |
          mkdir -p artifacts

          used_images=($(docker images --format "{{.Repository}}:{{.Tag}}" | tr ' ' "\n"))
          for image in "${used_images[@]}"
          do
            image_short_name=$(grep -oP "(?<=/$ENV/).*?(?=:)" <<< "$image" || grep -oP "(?<=/devops/).*?(?=:)" <<< "$image" || true)
            if [[ "$image_short_name" =~ .*"spawner".* ]];
            then
              echo "scanning $image"
              container_ids=($(docker ps -q -f "ancestor=$image" | tr ' ' "\n"))
              for container_id in "${container_ids[@]}"
              do
                container_name=$(docker inspect --format="{{.Name}}" $container_id)
                docker exec -t "$container_id" bash -c '
                  set -e

                  sudo apt update || apt update
                  export PATH="$HOME/.local/bin:$PATH"
                  python3 -m pip install --upgrade pip || wget https://bootstrap.pypa.io/get-pip.py -O - | python3
                  python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple movai-package-deployer==${{ env.PACKAGE_DEPLOYER_VERSION }}
                  package-deployer scan
                  ls -la /tmp
                ' || true
                  docker cp $container_id:/tmp/deployable.dploy artifacts/$container_name-noetic-deployable.dploy
                  docker cp $container_id:/tmp/undeployable.dploy artifacts/$container_name-noetic-3rdParty.dploy
              done
            else
              echo "Skipping scan of $image"
            fi
          done
          . .ci-venv/bin/activate
          package-deployer scan
          deactivate
          cp /tmp/deployable.dploy artifacts/simulator-noetic-deployable.dploy
          cp /tmp/undeployable.dploy artifacts/simulator-noetic-3rdParty.dploy

      - name: Stash deploy_artifacts_simulator_noetic
        uses: actions/upload-artifact@v4
        with:
          name: deploy_artifacts_simulator_noetic
          path: artifacts/*.dploy
          retention-days: 5

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          timeout 30 movai-cli remove --all || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  publish:
    needs: [Validations-Finish, Fleet-Validations, Simulator-Validations]
    runs-on: integration-pipeline
    outputs:
      slack_thread_id: ${{ needs.Validations-Finish.outputs.slack_thread_id }}
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v4

      - name: Agent info
        id: agent_info
        run: |
          echo "ip=$(hostname -I | awk '{print $1}')" | tee $GITHUB_OUTPUT

      - name: unstash robot_configs
        uses: actions/download-artifact@v4
        with:
          name: robot_configs
          path: .

      - name: unstash raised_meta
        uses: actions/download-artifact@v4
        with:
          name: raised_meta
          path: platform_configs

      - name: unstash deploy_artifacts_noetic
        uses: actions/download-artifact@v4
        with:
          name: deploy_artifacts_noetic
          path: artifacts

      - name: unstash deploy_artifacts_simulator_noetic
        uses: actions/download-artifact@v4
        with:
          name: deploy_artifacts_simulator_noetic
          path: artifacts

      - name: unstash deploy_simulator_artifacts
        uses: actions/download-artifact@v4
        with:
          name: deploy_simulator_artifacts
          path: .

      - name: Setup CI Scripts in .ci-venv
        shell: bash
        run: |
          python3 -m venv .ci-venv --clear --system-site-packages
          . .ci-venv/bin/activate
          [ -f ci-requirements.txt ] && pip install -r ci-requirements.txt
          python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed
          python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: Publish and create release
        id: prepare_publish
        shell: bash
        run: |
          set -m
          set -e
          . .ci-venv/bin/activate
          git config --global --add safe.directory $(pwd)
          git config --global user.name '${{ secrets.auto_commit_user }}'
          git config --global user.email '${{ secrets.auto_commit_mail }}'
          git config --global user.password ${{ secrets.auto_commit_pwd }}

          cp ./platform_configs/product.version product.version
          cp ./platform_configs/product-manifest.yaml product-manifest.yaml

          mkdir -p deployment_artifacts
          package-deployer join --dploy_workspace "$(pwd)/artifacts"
          integration-pipeline get_image_list_from_manifest --manifest_platform_base_key product_components --docker_registry $REGISTRY
          cp *.json deployment_artifacts
          cp artifacts/merged.dploy deployment_artifacts/deployable.dploy
          echo -e "$(cat ./artifacts/product.image.artifact)\n$(cat ./simulator.image.artifact)" > deployment_artifacts/product.image.artifact
          deactivate

          cp product.version deployment_artifacts
          cp product-manifest.yaml deployment_artifacts
          product_version=$(cat product.version)

          # danger zone. Everything will be deleted.
          mv product-manifest.yaml product-manifest.yaml.bck

          git restore product.version
          git restore product-manifest.yaml
          git pull

          # get previous version so we can generate the release report
          echo "previous_version=$(cat product.version)" >> $GITHUB_OUTPUT

          # write the raised version to be committed
          echo "$product_version" > product.version

          git add product.version
          git commit -m "[skip actions] Automatic Raise"
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare raise variables
        id: pre_raise
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT

      - name: Raise App version
        uses: CasperWA/push-protected@v2.14.0
        with:
          token: ${{ secrets.auto_commit_pwd }}
          branch: ${{ steps.pre_raise.outputs.branch }}
          unprotect_reviews: true

      - name: Github Publish
        shell: bash
        run: |
          commit_hash=$(git log --format="%H" -n 1)
          product_version=$(cat product.version)
          previous_version_option=""
          if gh release view ${{ steps.prepare_publish.outputs.previous_version }}  &>/dev/null; then
            previous_version_option="--notes-start-tag ${{ steps.prepare_publish.outputs.previous_version }}"
          fi
          gh release create -p --generate-notes $previous_version_option --target "$commit_hash" -t "${{ inputs.product_name }} $product_version" $product_version
          # add all files in the deployment_artifacts folder
          find deployment_artifacts -type f -exec gh release upload $product_version {} \;
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Update release notes
        shell: bash
        run: |
          # release version
          product_version=$(cat product.version)

          # get existent release body
          ORIGINAL_RN=$(gh release view "${product_version}" --json body | jq -r .body)
          echo -e "ORIGINAL_RN:\n ${ORIGINAL_RN}"

          # get release PRs
          PRS=$(echo "${ORIGINAL_RN}" | sed -rn "s/.* by @.* in https:\/\/github\.com\/${{ github.repository_owner }}\/${{ github.event.repository.name }}\/pull\/([0-9]+).*/\1/p" | tr '\n' ' ')
          # change to array
          PRS=($PRS)
          echo "Found the following PRs: ${PRS[@]}"

          # new release notes file
          rm -rf notes.txt

          # What's Changed - with info from PRs
          echo "## What's Changed" >> notes.txt

          if [ ${#PRS[@]} -eq 0 ]; then
              # no PRs exist
              echo "No relevant changes." >> notes.txt
          else
              # PRs exist
              for pr in "${PRS[@]}"; do
                  gh pr view "${pr}" --json body | jq -r .body >> notes.txt
              done
          fi
          echo "" >> notes.txt

          # PRs
          echo "## PRs" >> notes.txt
          if [ ${#PRS[@]} -eq 0 ]; then
              # no PRs exist
              echo "No PRs." >> notes.txt
          else
              # PRs exist
              echo "${ORIGINAL_RN}" | grep "\* .* by @.* in https://github.com/${{ github.repository_owner }}/" >> notes.txt
          fi
          echo "" >> notes.txt

          ## Diff
          echo "## Diff" >> notes.txt
          echo "${ORIGINAL_RN}" | grep "\*\*Full Changelog\*\*" >> notes.txt

          # set new release notes
          gh release edit "${product_version}" --notes-file notes.txt
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack
        run: |
          MESSAGE=":white_check_mark: CI: ${GITHUB_REPOSITORY} (${GITHUB_REF#refs/heads/}), build: $(cat product.version) (Attempt: #${{ github.run_attempt }}) is stable :sunny: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT

      - name: Slack message
        uses: archive/github-actions-slack@master
        with:
          slack-function: update-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-update-message-text: ${{ steps.pre_slack.outputs.msg }}
          slack-update-message-ts: ${{ needs.Validations-Finish.outputs.slack_thread_id }}



  Run-Status:
    runs-on: ubuntu-20.04
    needs: [publish, Validate-boostrap-configs]
    if: ${{ always() && ( needs.publish.result == 'failure' || needs.publish.result == 'cancelled'  || needs.publish.result == 'skipped') }}
    steps:
      - name: unstash raised_meta
        uses: actions/download-artifact@v4
        with:
          name: raised_meta
          path: platform_configs

      - name: Copy product configs
        shell: bash
        run: |
          cp ./platform_configs/product.version product.version
          cp ./platform_configs/product-manifest.yaml product-manifest.yaml

      - name: Prepare slack variables
        id: pre_slack
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY} (${GITHUB_REF#refs/heads/}), build: $(cat product.version) (Attempt: #${{ github.run_attempt }}) is unstable (or cancelled) :rain_cloud: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message
        uses: archive/github-actions-slack@master
        with:
          slack-function: update-message
          slack-bot-user-oauth-access-token: ${{ secrets.slack_token_id }}
          slack-channel: ${{ env.SLACK_CHANNEL }}
          slack-update-message-text: ${{ steps.pre_slack.outputs.msg_error }}
          slack-update-message-ts: ${{ needs.Validate-boostrap-configs.outputs.slack_thread_id }}
