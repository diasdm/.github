name: Build Packer images
on:
  workflow_call:
    inputs:
      product_name:
        required: true
        type: string
      ros_distro:
        required: true
        type: string
      continue_on_mobtest_error:
        required: false
        type: boolean
        default: false
      debug_fleet_keep_alive:
        required: false
        type: boolean
      fleet_ips:
        required: true
        type: string
      fleet_number_members:
        required: true
        type: number

    secrets:
      auto_commit_user:
        required: true
      auto_commit_mail:
        required: true
      auto_commit_pwd:
        required: true
      registry_user:
        required: true
      registry_password:
        required: true
      nexus_publisher_user:
        required: true
      nexus_publisher_password:
        required: true
      gh_token:
        required: true
      aws_key_id:
        required: true
      aws_secret_key_id:
        required: true
      slack_token_id:
        required: true
      ssh_pem_fleet_aws_vm:
        required: true
      proxmox_api_token_id:
        required: true
      proxmox_api_token_secret:
        required: true
      jira_username:
        required: true
      jira_password:
        required: true
      xray_clientid:
        required: true
      xray_secret:
        required: true
env:
  CI_INTEGRATION_SCRIPTS_VERSION: "2.1.0.23"
  MOBTEST_VERSION: "0.0.6.1"
  PACKAGE_DEPLOYER_VERSION: "1.0.0.25"
  GITHUB_API_USR: "OttoMation-Movai"
  AWS_ACCESS_KEY_ID: ${{ secrets.aws_key_id }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret_key_id }}
  AWS_DEFAULT_REGION: "us-east-1"
  REGISTRY: registry.cloud.mov.ai
  ENV: qa
  USERSPACE_FOLDER_PATH: userspace
  SIMULATION_ID: ci_simulation
  XRAY_CLIENTID: ${{ secrets.xray_clientid}}
  XRAY_SECRET: ${{ secrets.xray_secret}}
  JIRA_USERNAME: ${{ secrets.jira_username}}
  JIRA_PASSWORD: ${{ secrets.jira_password}}

jobs:
  Validate-boostrap-configs:
    runs-on: integration-pipeline
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Validate Manifest
        shell: bash
        run: |
          apt install -y yamllint
          yamllint product-manifest.yaml

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Bootstraping simulator metadata
        run: |
          git config --global --add safe.directory $(pwd)
          git fetch
          git checkout origin/${GITHUB_REF#refs/heads/} -- product.version
          cat product.version
          rm -rf simulator_artifacts ci_artifacts

          integration-pipeline generate_meta_simulator_artifacts \
                --manifest_platform_base_key product_components \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/}

          mkdir simulator_artifacts
          cp ci_artifacts/* ./simulator_artifacts

      - name: Bootstraping platform metadata
        run: |
          integration-pipeline generate_meta_artifacts \
                --manifest_platform_base_key product_components

      - name: Stash robot_configs
        uses: actions/upload-artifact@v3
        with:
          name: robot_configs
          path: "*.json*"

      - name: Stash sim_configs
        uses: actions/upload-artifact@v3
        with:
          name: sim_configs
          path: simulator_artifacts/*

      - name: raise
        run: |
          rm -rf simulator_artifacts ci_artifacts platform_configs
          mkdir platform_configs
          integration-pipeline raise
          cp product.version ./platform_configs/product.version
          cp product-manifest.yaml ./platform_configs/product-manifest.yaml

      - name: Stash raised_meta
        uses: actions/upload-artifact@v3
        with:
          name: raised_meta
          path: platform_configs/*

  Standalone-Validations:
    runs-on: ubuntu-20.04
    needs: [Validate-boostrap-configs]
    steps:
      - name: Pass through
        run: echo "Pass"

  Validation-UI-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA UI tests
        id: ui_tests_setup
        shell: bash
        run: |
          qa_key=ui_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/jira_report.txt /tmp/test_set.txt

          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.jira_report --output_file /tmp/jira_report.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          jira_report=$(cat /tmp/jira_report.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name

          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "jira_report=${jira_report}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT

          # setup venv in a step that is always executed
          pushd "${tests_dir}"
          rm -rf venv
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          deactivate
          popd

      - name: Feature File Validation
        id: feature_file_ui
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . venv/bin/activate

          python3 testcasemanagement/testcase_importer.py --target "${{ steps.ui_tests_setup.outputs.test_set }}"
          python3 testcasemanagement/feature_file_processor.py --validate

          deactivate

      - name: Prepare QA Feature File Validation slack message
        if: always()
        id: pre_slack
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: \
          UI tests feature file validation: ${{ steps.feature_file_ui.outcome }} \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02PB9A9F45"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Install
        id: install
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

          rm -rf artifacts
          mkdir -p artifacts
          cp *.json artifacts/

          CONFIG_FILE_NAME="basic-standalone-noetic.json"
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version

          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME

          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT

      - name: UI tests
        timeout-minutes: 120
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on host
          sudo apt install -y --allow-downgrades python3-rosnode python3-rosparam python3-rostopic
          export PYTHONPATH="${PYTHONPATH}:/usr/lib/python3/dist-packages"

          . venv/bin/activate

          # install test dependencies on spawner
          if [ -f apt-requirements.txt ]; then
            ## get spawner container name
            CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
            ## get apt dependencies
            APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
            ## install
            docker exec -t "${CONTAINER_ID}" bash -c "
              sudo apt update
              sudo apt install -y ${APT_DEPS}
            "
          fi

          if [ "${{ steps.ui_tests_setup.outputs.jira_report }}" == "True" ] ; then
            pytest \
              -ra \
              --hub_url http://selenoid-ui.hel.mov.ai \
              --browser_name chrome \
              --browser_version 91.0 \
              --base_url https://${{ steps.agent_info.outputs.ip }}/ \
              --movai-user ${{ steps.install.outputs.movai_user }} \
              --movai-pw ${{ steps.install.outputs.movai_pwd }} \
              --jira_report
          else
              pytest \
                -ra \
                --hub_url http://selenoid-ui.hel.mov.ai \
                --browser_name chrome \
                --browser_version 91.0 \
                --base_url https://${{ steps.agent_info.outputs.ip }}/ \
                --movai-user ${{ steps.install.outputs.movai_user }} \
                --movai-pw ${{ steps.install.outputs.movai_pwd }}
          fi

          deactivate

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.ui_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          # backend
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^backend-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # spawner
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^spawner-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # message-server
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^message-server-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          UI_DIR: ${{ steps.ui_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log and *.zip might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${UI_DIR}"/*.log ./qa_artifacts || true
          cp -r "${UI_DIR}"/*.tar ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: qa_artifacts_ui_tests
          path: qa_artifacts/*

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validation-Install-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA install tests
        id: install_tests_setup
        shell: bash
        run: |
          qa_key=install_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/jira_report.txt /tmp/test_set.txt

          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.jira_report --output_file /tmp/jira_report.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          jira_report=$(cat /tmp/jira_report.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "jira_report=${jira_report}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT

          # setup venv in a step that is always executed
          pushd "${tests_dir}"
          rm -rf venv
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          deactivate
          popd

      - name: Feature File Validation
        id: feature_file_install
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          . venv/bin/activate

          python3 testcasemanagement/testcase_importer.py --target "${{ steps.install_tests_setup.outputs.test_set }}"
          python3 testcasemanagement/feature_file_processor.py --validate

          deactivate

      - name: Prepare QA Feature File Validation slack message
        if: always()
        id: pre_slack
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: \
          Install tests feature file validation: ${{ steps.feature_file_install.outcome }} \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02PB9A9F45"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Install tests
        timeout-minutes: 45
        id: install
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          . venv/bin/activate
          rm -rf results/*

          if [ "${{ steps.install_tests_setup.outputs.jira_report }}" == "True" ] ; then
            pytest tests/ \
              -ra \
              -k '${{ steps.install_tests_setup.outputs.test_set }}' \
              --installPath="." --jsonConfigFilePath="../basic-standalone-noetic.json.ci" \
              --jira_report
          else
            pytest tests/ \
              -ra \
              -k '${{ steps.install_tests_setup.outputs.test_set }}' \
              --installPath="." --jsonConfigFilePath="../basic-standalone-noetic.json.ci"
          fi

          deactivate

          user=$(cat results/credentials.txt | awk -F: '{print $1}')
          pwd=$(cat results/credentials.txt | awk -F: '{print $2}')

          echo "movai_user=${user}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${pwd}" >> $GITHUB_OUTPUT

      - name: Run mobtest
        continue-on-error: ${{ inputs.continue_on_mobtest_error }}
        shell: bash
        run: |
          container_id=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
          docker exec -t "$container_id" bash -c '
            set -e
            export PATH="$HOME/.local/bin:$PATH"
            python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple mobtest==${{ env.MOBTEST_VERSION }} --ignore-installed
            mobtest proj /opt/ros/noetic/share/
            '

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.install_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          # backend
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^backend-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # spawner
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^spawner-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          INSTALL_DIR: ${{ steps.install_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${INSTALL_DIR}"/*.log ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/*.tar ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/results/*.log ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/results/*.zip ./qa_artifacts || true
          cp -r "${INSTALL_DIR}"/results/test_report_*.html ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: qa_artifacts_install_tests
          path: qa_artifacts/*

      - name: Collect Installed components
        shell: bash
        run: |
          mkdir -p artifacts

          used_images=($(docker images --format "{{.Repository}}:{{.Tag}}" | tr ' ' "\n"))
          for image in "${used_images[@]}"
          do
            image_short_name=$(grep -oP "(?<=/$ENV/).*?(?=:)" <<< "$image" || grep -oP "(?<=/devops/).*?(?=:)" <<< "$image" || true)
            if [[ "$image_short_name" =~ .*"backend".* || "$image_short_name" =~ .*"spawner".* || "$image_short_name" =~ .*"redis"*.* || "$image_short_name" =~ .*"health-node".* ]];
            then
              echo "scanning $image"
              container_ids=($(docker ps -q -f "ancestor=$image" | tr ' ' "\n"))
              for container_id in "${container_ids[@]}"
              do
                container_name=$(docker inspect --format="{{.Name}}" $container_id)
                docker exec -t "$container_id" bash -c '
                  set -e

                  sudo apt update || apt update
                  export PATH="$HOME/.local/bin:$PATH"
                  python3 -m pip install --upgrade pip || wget https://bootstrap.pypa.io/get-pip.py -O - | python3
                  python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple movai-package-deployer==${{ env.PACKAGE_DEPLOYER_VERSION }}
                  package-deployer scan
                  ls -la /tmp
                ' || true
                  docker cp $container_id:/tmp/deployable.dploy artifacts/$container_name-noetic-deployable.dploy
                  docker cp $container_id:/tmp/undeployable.dploy artifacts/$container_name-noetic-3rdParty.dploy
              done
            else
              echo "Skipping scan of $image"
            fi
          done
          export PATH="$HOME/.local/bin:$PATH"
          package-deployer scan
          cp /tmp/deployable.dploy artifacts/host-noetic-deployable.dploy
          cp /tmp/undeployable.dploy artifacts/host-noetic-3rdParty.dploy

      - name: Stash deploy_artifacts_noetic
        uses: actions/upload-artifact@v3
        with:
          name: deploy_artifacts_noetic
          path: artifacts/*.dploy

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          INSTALL_DIR: ${{ steps.install_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validation-API-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA API tests
        id: api_tests_setup
        shell: bash
        run: |
          qa_key=api_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          export PATH="$HOME/.local/bin:$PATH"

          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT

          # setup venv in a step that is always executed
          pushd "${tests_dir}"
          rm -rf venv
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          deactivate
          popd

      - name: Install
        id: install
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

          mkdir -p artifacts
          cp *.json artifacts/
          CONFIG_FILE_NAME="basic-standalone-noetic.json"
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version

          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT

      - name: API tests
        timeout-minutes: 30
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on host
          sudo apt install -y --allow-downgrades python3-rosnode python3-rosparam python3-rostopic
          export PYTHONPATH="${PYTHONPATH}:/usr/lib/python3/dist-packages"

          . venv/bin/activate

          pytest src/tests \
              --base_url https://${{ steps.agent_info.outputs.ip }} \
              --username ${{ steps.install.outputs.movai_user }} \
              --password ${{ steps.install.outputs.movai_pwd }}

          deactivate

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.api_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          # backend
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^backend-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # spawner
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^spawner-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # message-server
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^message-server-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          API_DIR: ${{ steps.api_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log and *.zip might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${API_DIR}"/*.log ./qa_artifacts || true
          cp -r "${API_DIR}"/*.tar ./qa_artifacts || true
          cp -r "${API_DIR}"/results/*.zip ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: qa_artifacts_api_tests
          path: qa_artifacts/*

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validation-Flow-Tests:
    needs: [Standalone-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: Patch robot_configs *.ci with the right full path
        shell: bash
        run: |
          find -L . -type f -name '*.json.ci' -exec \
            sed -i "s;/__w;$(pwd)/../..;g" {} \
           \;

      - name: Setup QA Flow tests
        id: flow_tests_setup
        shell: bash
        run: |
          qa_key=flow_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/test_set.txt
          export PATH="$HOME/.local/bin:$PATH"

          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "version=${tests_version}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT

          # setup venv in a step that is always executed
          pushd "${tests_dir}"
          rm -rf venv
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          deactivate
          popd

      - name: Install
        id: install
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

          mkdir -p artifacts
          cp *.json artifacts/
          CONFIG_FILE_NAME="basic-standalone-noetic.json"
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version

          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT
          execution_status=$?
          exit $execution_status
          rm movai_service_version

      - name: Flow tests
        timeout-minutes: 30
        working-directory: ${{ steps.flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on host
          sudo apt install -y --allow-downgrades python3-rosnode python3-rosparam python3-rostopic
          export PYTHONPATH="${PYTHONPATH}:/usr/lib/python3/dist-packages"

          # install test dependencies on spawner
          if [ -f apt-requirements.txt ]; then
            ## get spawner container name
            CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
            ## get apt dependencies
            APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
            ## install
            docker exec -t "${CONTAINER_ID}" bash -c "
              sudo apt update
              sudo apt install -y ${APT_DEPS}
            "
          fi

          # run tests
          . venv/bin/activate

          pytest \
            -s \
            -ra \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            -m '${{ steps.flow_tests_setup.outputs.test_set }}' \
            --tb=short

          deactivate

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          # backend
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^backend-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # spawner
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^spawner-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # message-server
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^message-server-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          FLOW_DIR: ${{ steps.flow_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts, they might not exist
          mkdir -p qa_artifacts
          cp -r "${FLOW_DIR}"/*.log ./qa_artifacts || true
          cp -r "${FLOW_DIR}"/*.tar ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: qa_artifacts_flow_tests
          path: qa_artifacts/*

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Validations-Finish:
    needs: [Validation-UI-Tests, Validation-Install-Tests, Validation-API-Tests, Validation-Flow-Tests]
    runs-on: ubuntu-20.04
    steps:
      - name: Pass through
        run: echo "Pass"

  Fleet-Validations:
    needs: [Validate-boostrap-configs]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash robot_configs
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: Provision remote vms (AWS)
        if: ${{ false }}
        shell: bash
        run: |
          mkdir aws_artifacts
          python3 -m pip install awscli
          cd staging
          export PATH="$HOME/.local/bin:$PATH"
          export product="platform"
          export version="$PRODUCT_RELEASE_VERSION"
          ./ec2_provision.sh
          cp -vf infra_ids.txt ../aws_artifacts/

      - name: Stash ci_infra_artifacts (AWS)
        if: ${{ false }}
        uses: actions/upload-artifact@v3
        with:
          name: ci_infra_artifacts
          path: aws_artifacts/*

      - name: Install terraform
        shell: bash
        run: |
          wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
          sudo apt update && sudo apt install terraform -y

      - name: Setup terraform proxmox provisioner
        id: provision_infra_setup
        shell: bash
        run: |
          provision_infra_dir=provision_scripts
          provision_infra_version=0.0.1-38
          provision_infra_repo_name=devops-tf-proxmox-fleet

          rm -rf $provision_infra_dir
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline fetch_by_tag --repo $provision_infra_repo_name --version $provision_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $provision_infra_dir
          ls -la $provision_infra_dir
          echo "target_dir=${provision_infra_dir}/hosts/generic/" >> $GITHUB_OUTPUT

      - name: Define Instance names
        id: infra_names
        shell: bash
        run: |
          branch=$(echo ${GITHUB_REF#refs/heads/} | sed "s;\.;-;g" )

          local_manager_prefix="ip-$branch-manager"
          local_worker_prefix="ip-$branch-worker"
          echo "$local_manager_prefix"
          echo "$local_worker_prefix"

          echo "manager_prefix=${local_manager_prefix}" >> $GITHUB_OUTPUT
          echo "worker_prefix=${local_worker_prefix}" >> $GITHUB_OUTPUT

      - name: Provision remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        shell: bash
        run: |
          terraform init -backend-config="key=hel-fleet-${{ steps.infra_names.outputs.manager_prefix }}.tfstate"
          terraform plan
          terraform apply -auto-approve
        env:
          TF_VAR_number_agents: ${{ inputs.fleet_number_members }}
          TF_VAR_proxmox_api_url: "https://hel.mov.ai:8006/api2/json"
          TF_VAR_proxmox_api_token_id: ${{ secrets.proxmox_api_token_id }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.proxmox_api_token_secret }}
          TF_VAR_provision_ssh_pem: ${{ secrets.ssh_pem_fleet_aws_vm }}
          TF_VAR_ip_list: ${{ inputs.fleet_ips }}
          TF_VAR_proxmox_host: "hel"
          TF_VAR_vm_gateway: "172.22.0.1"
          TF_VAR_ip_mask: 24
          TF_VAR_bios: "seabios"
          TF_VAR_pool: "IP-Temp-VMs"
          TF_VAR_tags: "ip-fleet"

          TF_VAR_fleet_hosts_user: "devops"
          TF_VAR_template_name: "ubuntu-2004-cloudinit-template2"
          TF_VAR_fleet_manager_name: ${{ steps.infra_names.outputs.manager_prefix }}
          TF_VAR_fleet_manager_memory: 8192
          TF_VAR_template_name_no_gpu: "ubuntu-2004-cloudinit-template2"
          TF_VAR_fleet_worker_name_prefix: ${{ steps.infra_names.outputs.worker_prefix }}
          TF_VAR_fleet_worker_memory: 8192

      - name: Prepare Devops provisioning slack message
        if: always()
        id: pre_slack_infra
        run: |
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is being impacted by an infrastructural issue. \
          Provisioning of fleet infrastructure failed. Please take a look! \
          Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "G0102LEV1CL"
          slack-message: ${{ steps.pre_slack_infra.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Apply ansible inventory
        shell: bash
        run: |
          cp ${{ steps.provision_infra_setup.outputs.target_dir }}/hosts staging/hosts
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file staging/hosts --key fleet.children.managers.hosts.manager.ansible_host --output_file ./staging/manager_private_ip.txt

      - name: Setup ansible installation
        id: ansible_install_setup
        shell: bash
        run: |
          install_key=ansible_deploy

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.installion.$install_key.name --output_file /tmp/repo_name.txt
          install_infra_dir=$(cat /tmp/target_dir.txt)
          install_infra_version=$(cat /tmp/version.txt)
          install_infra_repo_name=$(cat /tmp/repo_name.txt)

          rm -rf $install_infra_repo_name
          integration-pipeline fetch_by_tag --repo $install_infra_repo_name --version $install_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $install_infra_dir
          ls -la $install_infra_dir
          echo "target_dir=${install_infra_dir}" >> $GITHUB_OUTPUT

      - name: Ansible install platform
        working-directory: ${{ steps.ansible_install_setup.outputs.target_dir }}
        shell: bash
        run: |

          function ensure_agent_up(){
            vm_ip=$1
            i="0"
            max=15
            success=1
            while [ $success -ne 0 ]
            do
            echo "Checking if $vm_ip is reachable ($i/$max)"
            ping -c1 $vm_ip &>/dev/null
            success=$?

            if [ $i -lt $max ]
            then
              i=$[$i+1]
            else
              echo "Timeout waiting for $vm_ip"
              exit 2
            fi

            sleep 2
            done

          }
          echo "${{ secrets.ssh_pem_fleet_aws_vm }}" > ~/.ssh/aws_slave.pem
          sudo chmod 600 ~/.ssh/aws_slave.pem
          while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 ; do echo Waiting for other software managers to finish... ; sleep 5;done
          sudo apt install -y python3.9 python3.9-venv
          python3.9 -m venv ansible-venv
          source ansible-venv/bin/activate
          python3 -m pip install -r requirements.txt
          ansible-galaxy install -r requirements.yml --timeout 120

          stripped_ips=$(echo ${{ inputs.fleet_ips }} | sed "s;\[;;g" | sed "s;];;g" | sed "s; ;;g")
          touch ~/.ssh/known_hosts
          sudo chmod 600 ~/.ssh/known_hosts
          IFS=',' read -r -a stripped_ips_arr <<< $stripped_ips
          for ip in "${stripped_ips_arr[@]}"
          do
            ensure_agent_up $ip
            ssh-keygen -f ~/.ssh/known_hosts -R $ip
            ssh-keyscan -H $ip >> ~/.ssh/known_hosts
          done

          ansible-playbook install.yml \
           -i ../staging/hosts \
           --key-file ~/.ssh/aws_slave.pem \
           --extra-vars=@"$(pwd)/.."/product-manifest.yaml \
           -e fleet_domain_dns="" \
           -e "{\"proxycerts__remote_redis_servers_fqn\": [$(cat ../staging/manager_private_ip.txt)]}" \
           -e '{"fleet_extra_hosts": ["172.22.0.106    registry.hel.mov.ai traefik"]}' \
           --skip-tags "ufw,hardening"
          execution_status=$?
          deactivate
          exit $execution_status

      - name: Collect Fleet QA artifacts
        working-directory: ${{ steps.ansible_install_setup.outputs.target_dir }}
        if: always()
        shell: bash
        run: |
          mkdir -p fleet_qa_artifacts/install
          source ansible-venv/bin/activate
          # install fleet_tests artifacts
          for fleet_host in "manager" "member1" "member2"; do
            ansible $fleet_host -i ../staging/hosts --key-file ~/.ssh/aws_slave.pem -m shell -a 'journalctl -u movai-service' > fleet_qa_artifacts/install/$fleet_host.log || true
          done
          deactivate

      - name: Stash Fleet QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: fleet_qa_artifacts
          path: ${{ steps.ansible_install_setup.outputs.target_dir }}/fleet_qa_artifacts/*

      - name: Teardown remote vms (AWS)
        if: ${{ false }}
        shell: bash
        run: |
          echo "Deleting $(cat aws_artifacts/infra_ids.txt)"
          python3 -m pip install awscli
          export PATH="$HOME/.local/bin:$PATH"
          aws ec2 terminate-instances --instance-ids $(cat aws_artifacts/infra_ids.txt)
          echo "Deleting $(cat aws_artifacts/infra_ids.txt)"
          python3 -m pip install awscli
          export PATH="$HOME/.local/bin:$PATH"
          aws ec2 terminate-instances --instance-ids $(cat aws_artifacts/infra_ids.txt)

      - name: Teardown remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        if: ${{ success() || cancelled() || ( !inputs.debug_fleet_keep_alive && failure() ) }}
        shell: bash
        run: terraform destroy -auto-approve
        env:
          TF_VAR_number_agents: ${{ inputs.fleet_number_members }}
          TF_VAR_proxmox_api_url: "https://hel.mov.ai:8006/api2/json"
          TF_VAR_proxmox_api_token_id: ${{ secrets.proxmox_api_token_id }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.proxmox_api_token_secret }}
          TF_VAR_provision_ssh_pem: ${{ secrets.ssh_pem_fleet_aws_vm }}
          TF_VAR_ip_list: ${{ inputs.fleet_ips }}

  Build-Simulator:
    needs: [Validate-boostrap-configs]
    runs-on: integration-pipeline
    env:
      DISTRO: noetic
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash sim_configs
        uses: actions/download-artifact@v3
        with:
          name: sim_configs
          path: simulator_artifacts

      - name: Prepare Skip variables
        id: pre_simulator_build
        run: |
          if [ ! -f "simulator_artifacts/version" ]; then
            echo "skip_simulator_build=true" >> $GITHUB_OUTPUT
          else
            echo "skip_simulator_build=false" >> $GITHUB_OUTPUT
          fi

      - name: Lint docker image
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          wget https://github.com/hadolint/hadolint/releases/download/v2.9.3/hadolint-Linux-x86_64
          chmod +x hadolint-Linux-x86_64
          ./hadolint-Linux-x86_64 docker/$DISTRO/Dockerfile-simulator -t error

      - name: Download models
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline fetch_simulator_models \
                --manifest_platform_base_key product_components \
                --gh_api_user $GITHUB_API_USR \
                --gh_api_pwd ${{ secrets.auto_commit_pwd }} \
                --target_dir "./models"
          if [ ! -d ./models ]; then mkdir -p ./models; fi

      - name: Login to Private Registry
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.REGISTRY }}

      - name: Prepare docker build variables
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        id: pre_build
        run: |
          echo "image_name=$(cat simulator_artifacts/simulator_name.ci)" >> $GITHUB_OUTPUT
          echo "base_name=$(cat simulator_artifacts/simulator_base.ci)" >> $GITHUB_OUTPUT

      - name: Build with args and push:${{ inputs.deploy }}
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        uses: docker/build-push-action@v3
        with:
          context: .
          platforms: linux/amd64
          file: docker/${{ env.DISTRO }}/Dockerfile-simulator
          push: true
          tags: "${{ env.REGISTRY }}/qa/${{ steps.pre_build.outputs.image_name }}"
          pull: true
          build-args: |
            BASE_IMAGE=${{ steps.pre_build.outputs.base_name }}
            CI_SCRIPT_VERSION=${{ env.CI_INTEGRATION_SCRIPTS_VERSION }}

      - name: Collect Installed components
        if: ${{ steps.pre_simulator_build.outputs.skip_simulator_build == 'false' }}
        shell: bash
        run: |
          cd simulator_artifacts
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline publish_simulator_state_artifacts \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/}

      - name: pre-stash
        shell: bash
        run: |
          echo "$REGISTRY/qa/$(cat simulator_artifacts/simulator_name.ci)" > simulator.image.artifact

      - name: Stash deploy_simulator_artifacts
        uses: actions/upload-artifact@v3
        with:
          name: deploy_simulator_artifacts
          path: simulator.image.artifact

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Simulator-Validations:
    needs: [Build-Simulator]
    runs-on: integration-pipeline
    steps:
      - uses: rtCamp/action-cleanup@master

      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        run: |
          echo "public ip: $(curl ipinfo.io/ip)"
          echo "private ip: $(hostname -I | awk '{print $1}')"

      - name: unstash raised_meta
        uses: actions/download-artifact@v3
        with:
          name: raised_meta
          path: .

      - name: unstash sim_configs
        uses: actions/download-artifact@v3
        with:
          name: sim_configs
          path: simulator_artifacts

      - name: unstash robot_jsons_noetic
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: Login to Private Registry
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.REGISTRY }}

      - name: Setup QA Flow tests
        id: sim_flow_tests_setup
        shell: bash
        run: |
          qa_key=flow_tests

          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/test_set.txt
          export PATH="$HOME/.local/bin:$PATH"

          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
          integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt

          tests_dir=$(cat /tmp/target_dir.txt)
          tests_version=$(cat /tmp/version.txt)
          tests_repo_name=$(cat /tmp/repo_name.txt)
          test_set=$(cat /tmp/test_set.txt)

          rm -rf $tests_repo_name
          integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
          ls -la $tests_dir

          echo "target_dir=${tests_dir}" >> $GITHUB_OUTPUT
          echo "version=${tests_version}" >> $GITHUB_OUTPUT
          echo "test_set=${test_set}" >> $GITHUB_OUTPUT

          # setup venv in a step that is always executed
          pushd "${tests_dir}"
          rm -rf venv
          python3 -m venv venv
          . venv/bin/activate
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          deactivate
          popd

      - name: Installation
        id: install
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

          mkdir -p artifacts
          cp *.json artifacts/

          CONFIG_FILE_NAME="basic-standalone-ignition-noetic.json"
          mkdir -p userspace/

          export USERSPACE_FOLDER_PATH="$(pwd)/userspace"
          export PUBLIC_IP=$(hostname -I | awk '{print $1}')

          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version

          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          echo "movai_user=${MOVAI_USER}" >> $GITHUB_OUTPUT
          echo "movai_pwd=${MOVAI_PWD}" >> $GITHUB_OUTPUT
        env:
          SIMULATION_ID: "CI"

      - name: Simulator tests
        timeout-minutes: 30
        working-directory: ${{ steps.sim_flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # install test dependencies on host
          sudo apt install -y --allow-downgrades python3-rosnode python3-rosparam python3-rostopic
          export PYTHONPATH="${PYTHONPATH}:/usr/lib/python3/dist-packages"

          # install test dependencies on spawner
          ## get spawner container name
          CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
          ## get apt dependencies
          APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
          ## install
          docker exec -t "${CONTAINER_ID}" bash -c "
            sudo apt update
            sudo apt install -y ${APT_DEPS}
          "

          # run tests
          . venv/bin/activate

          pytest \
            -s \
            -ra \
            --movai-user ${{ steps.install.outputs.movai_user }} \
            --movai-pw ${{ steps.install.outputs.movai_pwd }} \
            -m 'simulator' \
            --tb=short

          deactivate

      - name: Save docker container logs
        if: always()
        working-directory: ${{ steps.sim_flow_tests_setup.outputs.target_dir }}
        shell: bash
        run: |
          # for sanity
          docker ps -a

          # backend
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^backend-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # spawner
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^spawner-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # message-server
          CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^message-server-.*")
          docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

          # movai-service
          journalctl -u movai-service --since '1hour ago' &> "movai-service.log"

      - name: Stash QA artifacts
        if: always()
        shell: bash
        env:
          SIM_DIR: ${{ steps.sim_flow_tests_setup.outputs.target_dir }}
        run: |
          # cleanup
          rm -rf qa_artifacts

          # tests artifacts
          # *.log might not exist if the test fails early
          mkdir -p qa_artifacts
          cp -r "${SIM_DIR}"/*.log ./qa_artifacts || true
          cp -r "${SIM_DIR}"/*.tar ./qa_artifacts || true

      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: qa_artifacts_simulator_tests
          path: qa_artifacts/*

      - name: Collect Installed components
        shell: bash
        run: |
          mkdir -p artifacts

          used_images=($(docker images --format "{{.Repository}}:{{.Tag}}" | tr ' ' "\n"))
          for image in "${used_images[@]}"
          do
            image_short_name=$(grep -oP "(?<=/$ENV/).*?(?=:)" <<< "$image" || grep -oP "(?<=/devops/).*?(?=:)" <<< "$image" || true)
            if [[ "$image_short_name" =~ .*"spawner".* ]];
            then
              echo "scanning $image"
              container_ids=($(docker ps -q -f "ancestor=$image" | tr ' ' "\n"))
              for container_id in "${container_ids[@]}"
              do
                container_name=$(docker inspect --format="{{.Name}}" $container_id)
                docker exec -t "$container_id" bash -c '
                  set -e

                  sudo apt update || apt update
                  export PATH="$HOME/.local/bin:$PATH"
                  python3 -m pip install --upgrade pip || wget https://bootstrap.pypa.io/get-pip.py -O - | python3
                  python3 -m pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple movai-package-deployer==${{ env.PACKAGE_DEPLOYER_VERSION }}
                  package-deployer scan
                  ls -la /tmp
                ' || true
                  docker cp $container_id:/tmp/deployable.dploy artifacts/$container_name-noetic-deployable.dploy
                  docker cp $container_id:/tmp/undeployable.dploy artifacts/$container_name-noetic-3rdParty.dploy
              done
            else
              echo "Skipping scan of $image"
            fi
          done
          export PATH="$HOME/.local/bin:$PATH"
          package-deployer scan
          cp /tmp/deployable.dploy artifacts/simulator-noetic-deployable.dploy
          cp /tmp/undeployable.dploy artifacts/simulator-noetic-3rdParty.dploy

      - name: Stash deploy_artifacts_simulator_noetic
        uses: actions/upload-artifact@v3
        with:
          name: deploy_artifacts_simulator_noetic
          path: artifacts/*.dploy

      - name: Remove robots
        if: always()
        shell: bash
        run: |
          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  publish:
    needs: [Validations-Finish, Fleet-Validations, Simulator-Validations]
    runs-on: integration-pipeline
    steps:
      - name: Cleanup Workspace
        uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3
      - name: Agent info
        id: agent_info
        run: |
          ip=$(hostname -I | awk '{print $1}')
          echo $ip
          echo "ip=${ip}" >> $GITHUB_OUTPUT
      - name: unstash robot_configs
        uses: actions/download-artifact@v3
        with:
          name: robot_configs
          path: .

      - name: unstash raised_meta
        uses: actions/download-artifact@v3
        with:
          name: raised_meta
          path: platform_configs

      - name: unstash deploy_artifacts_noetic
        uses: actions/download-artifact@v3
        with:
          name: deploy_artifacts_noetic
          path: artifacts

      - name: unstash deploy_artifacts_simulator_noetic
        uses: actions/download-artifact@v3
        with:
          name: deploy_artifacts_simulator_noetic
          path: artifacts

      - name: unstash deploy_simulator_artifacts
        uses: actions/download-artifact@v3
        with:
          name: deploy_simulator_artifacts
          path: .

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Install Package Deployer
        shell: bash
        run: python3 -m pip install movai-package-deployer==$PACKAGE_DEPLOYER_VERSION --ignore-installed

      - name: Publish and create release
        shell: bash
        run: |
          set -m
          set -e

          export PATH="$HOME/.local/bin:$PATH"
          git config --global --add safe.directory $(pwd)
          git config --global user.name '${{ secrets.auto_commit_user }}'
          git config --global user.email '${{ secrets.auto_commit_mail }}'
          git config --global user.password ${{ secrets.auto_commit_pwd }}

          cp ./platform_configs/product.version product.version
          cp ./platform_configs/product-manifest.yaml product-manifest.yaml

          mkdir -p deployment_artifacts
          package-deployer join --dploy_workspace "$(pwd)/artifacts"
          integration-pipeline get_image_list_from_manifest --manifest_platform_base_key product_components --docker_registry $REGISTRY
          cp *.json deployment_artifacts
          cp artifacts/merged.dploy deployment_artifacts/deployable.dploy
          echo -e "$(cat ./artifacts/product.image.artifact)\n$(cat ./simulator.image.artifact)" > deployment_artifacts/product.image.artifact

          cp product.version deployment_artifacts
          cp product-manifest.yaml deployment_artifacts
          product_version=$(cat product.version)

          # danger zone. Everything will be deleted.
          mv product-manifest.yaml product-manifest.yaml.bck

          git restore product.version
          git restore product-manifest.yaml
          git pull
          echo "$product_version" > product.version

          git add product.version
          git commit -m "[skip actions] Automatic Raise"
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare raise variables
        id: pre_raise
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT

      - name: Raise App version
        uses: CasperWA/push-protected@v2.14.0
        with:
          token: ${{ secrets.auto_commit_pwd }}
          branch: ${{ steps.pre_raise.outputs.branch }}
          unprotect_reviews: true

      - name: Github Publish
        shell: bash
        run: |
          commit_hash=$(git log --format="%H" -n 1)
          product_version=$(cat product.version)
          gh release create -p --generate-notes --target "$commit_hash" -t "${{ inputs.product_name }} $product_version" $product_version
          # add all files in the deployment_artifacts folder
          find deployment_artifacts -type f -exec gh release upload $product_version {} \;
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Update release notes
        shell: bash
        run: |
          # release version
          product_version=$(cat product.version)

          # get existent release body
          ORIGINAL_RN=$(gh release view "${product_version}" --json body | jq -r .body)
          echo -e "ORIGINAL_RN:\n ${ORIGINAL_RN}"

          # get release PRs
          PRS=$(echo "${ORIGINAL_RN}" | sed -rn "s/.* by @.* in https:\/\/github\.com\/${{ github.repository_owner }}\/${{ github.event.repository.name }}\/pull\/([0-9]+).*/\1/p" | tr '\n' ' ')
          # change to array
          PRS=($PRS)
          echo "Found the following PRs: ${PRS[@]}"

          # new release notes file
          rm -rf notes.txt

          # What's Changed - with info from PRs
          echo "## What's Changed" >> notes.txt

          if [ ${#PRS[@]} -eq 0 ]; then
              # no PRs exist
              echo "No relevant changes." >> notes.txt
          else
              # PRs exist
              for pr in "${PRS[@]}"; do
                  gh pr view "${pr}" --json body | jq -r .body >> notes.txt
              done
          fi
          echo "" >> notes.txt

          # PRs
          echo "## PRs" >> notes.txt
          if [ ${#PRS[@]} -eq 0 ]; then
              # no PRs exist
              echo "No PRs." >> notes.txt
          else
              # PRs exist
              echo "${ORIGINAL_RN}" | grep "\* .* by @.* in https://github.com/${{ github.repository_owner }}/" >> notes.txt
          fi
          echo "" >> notes.txt

          ## Diff
          echo "## Diff" >> notes.txt
          echo "${ORIGINAL_RN}" | grep "\*\*Full Changelog\*\*" >> notes.txt

          # set new release notes
          gh release edit "${product_version}" --notes-file notes.txt
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Propagate release
        continue-on-error: true
        shell: bash
        run: |
          gh workflow run "Propagate EE" --repo MOV-AI/qa-automations
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

      - name: Prepare slack variables
        if: always()
        id: pre_slack
        run: |
          MESSAGE=":white_check_mark: CI: ${GITHUB_REPOSITORY} (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is stable :sunny: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          MESSAGE_ERR=":x: CI: ${GITHUB_REPOSITORY}, (${GITHUB_REF#refs/heads/}), build: $(cat product.version) is unstable :rain_cloud: Details: https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}"
          echo "msg=${MESSAGE}" >> $GITHUB_OUTPUT
          echo "msg_error=${MESSAGE_ERR}" >> $GITHUB_OUTPUT

      - name: Slack message success
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02U028NMB7"
          slack-message: ${{ steps.pre_slack.outputs.msg }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}

      - name: Slack message failure
        if: failure()
        uses: slackapi/slack-github-action@v1.23.0
        with:
          channel-id: "C02U028NMB7"
          slack-message: ${{ steps.pre_slack.outputs.msg_error }}
        env:
          SLACK_BOT_TOKEN: ${{ secrets.slack_token_id }}
