name: Build and pack py packages
on:
  workflow_call:
    inputs:
      deploy:
        required: false
        type: string
        default: 'false'
      release:
        required: false
        type: string
        default: 'false'
      skip_linting:
        required: false
        type: string
        default: 'false'
        description: DEPRECATED - to be removed on v2
      run_black:
        required: false
        type: string
        default: 'false'
        description: When 'true' black is run stopping the pipeline if any files are not properly formatted
      skip_testing:
        required: false
        type: string
        default: 'false'
      package_paths:
        required: false
        type: string
        default: '["./"]'
      rpm_build:
        required: false
        type: string
        default: 'false'
      install_test:
        required: false
        type: string
        default: 'true'
      install_test_docker:
        required: false
        type: string
        default: 'false'
      install_test_zmq:
        required: false
        type: string
        default: 'false'
      prod_publish_repos:
        required: false
        type: string
        default: '["ppa-main"]'
      prod_publish_pypi:
        required: false
        type: string
        default: 'pypi-edge'
      skip_sonar:
        required: false
        type: boolean
        default: true
    secrets:
      auto_commit_user:
        required: true
      auto_commit_mail:
        required: true
      auto_commit_pwd:
        required: true
      registry_user:
        required: true
      registry_password:
        required: true
      nexus_publisher_user:
        required: true
      nexus_publisher_password:
        required: true
      gh_token:
        required: true
      sonar_token:
        required: true

jobs:
  RefreshSource:
    if: ${{ inputs.deploy == 'false' && inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    steps:
      - uses: docker://chinthakagodawita/autoupdate-action:v1
        continue-on-error: true
        env:
          GITHUB_TOKEN: '${{ secrets.auto_commit_pwd }}'
          MERGE_MSG: "Branch was auto-updated."

  StaticAnalysis:
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}

    steps:
    - name: Checkout
      uses: actions/checkout@v3
      with:
        # Disabling shallow clone is recommended for improving relevancy of reporting
        fetch-depth: 0
        submodules: recursive

    - name: Create hard link to pip 3.8
      run: |
        ln /usr/bin/pip3 /usr/bin/pip3.8

    - name: Install build-requirements
      run: |
        if [ -f build-apt-requirements.txt ]; then
          apt update
          echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections
          apt install -y $(grep -vE "^\s*#" build-apt-requirements.txt  | tr "\n" " ")
        fi
        python3 -m pip install -r build-requirements.txt

    - name: Run Black
      if: ${{ inputs.run_black == 'true' }}
      run: |
        python3 -m black \
          --line-length 100 \
          --diff \
          --check \
          .

    - name: Python Linters
      # run linters isolated so no issues are masked from SonarCloud
      run: |
        python3 -m flake8 \
          --isolated \
          --exclude dist,.*\.egg-info,.git,__pycache__,.tox,venv \
          --max-complexity 10 \
          --max-line-length 100 \
          --exit-zero \
          --output-file flake8-report.txt

        # pylint seems to not have a way to ignore configuration files
        # so we need to provide it a dummy one
        touch dummy-pylint-config
        python3 -m pylint \
          --rcfile dummy-pylint-config \
          --ignore-patterns dist,.*\.egg-info,.git,__pycache__,.tox,venv \
          --max-line-length 100 \
          --exit-zero \
          --recursive y \
          --output pylint-report.txt \
        .

    - name: Store python Linters files
      uses: actions/upload-artifact@v3
      with:
        name: linting_reports
        path: "./*-report.txt"
        retention-days: 5

  Build:
    needs: [StaticAnalysis]
    strategy:
        matrix:
          pack_path: ${{ fromJSON(inputs.package_paths) }}
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    outputs:
      package_name: ${{ steps.vars.outputs.py_pkg_name }}
      package_version: ${{ steps.releasevars.outputs.py_pkg_version }}

    steps:
    - name: Checkout
      uses: actions/checkout@v3
      with:
        # Disabling shallow clone is recommended for improving relevancy of reporting
        fetch-depth: 0
        submodules: recursive

    - name: install build-requirements
      run: python3 -m pip install -r build-requirements.txt

    - name: Create links for package ${{ matrix.pack_path }}
      run: |
        ln -f ${{ matrix.pack_path }}/debian/setup.py setup.py
        ln -sf ${{ matrix.pack_path }}/debian debian

    - name: Raise version locally
      if: ${{ inputs.deploy == 'true' }}
      run: bump2version build setup.py --no-tag --no-commit --allow-dirty

    - name: Find Package details
      id: vars
      run: |
        PACKAGE_VERSION=$(cat .bumpversion.cfg | sed s/' '/''/g | grep 'current_version=' | sed s/'current_version='/''/g)
        PACKAGE_NAME=$(cat setup.py | grep name | cut -d '"' -f2)

        echo "py_pkg_name=$PACKAGE_NAME" >> $GITHUB_OUTPUT
        echo "py_pkg_version=$PACKAGE_VERSION" >> $GITHUB_OUTPUT

    - name: Sync setup.py
      run: sed -i s/"$(cat setup.py | grep version=)"/"    version=\"${{ steps.vars.outputs.py_pkg_version }}\","/g setup.py

    - name: Enable 4 digit version
      id: releasevars
      run: |
        PACKAGE_RELEASE_VERSION=$(echo ${{ steps.vars.outputs.py_pkg_version }} | sed s/"-"/"."/g)
        sed -i s/"$(cat setup.py | grep version=)"/"$(cat setup.py | grep version= | sed s/"-"/"."/g)"/g setup.py

        echo "py_pkg_version=$PACKAGE_RELEASE_VERSION" >> $GITHUB_OUTPUT

    - name: Build
      run: python3 -m build

    - name: Archive binary
      uses: actions/upload-artifact@v3
      with:
        name: packages
        path: dist/*
        retention-days: 5

    - name: Publish package to TestPyPI Experimental
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: ${{ secrets.nexus_publisher_user }}
        password: ${{ secrets.nexus_publisher_password }}
        repository-url: https://artifacts.cloud.mov.ai/repository/pypi-experimental/

    - name: Publish package to TestPyPI Testing
      if: ${{ inputs.deploy == 'true' }}
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: ${{ secrets.nexus_publisher_user }}
        password: ${{ secrets.nexus_publisher_password }}
        repository-url: https://artifacts.cloud.mov.ai/repository/pypi-integration/

    - name: Remove hardlinks for package ${{ matrix.pack_path }}
      run: |
        rm -f setup.py
        rm -f debian

  Raise:
    needs: [Build]
    if: ${{ inputs.release == 'false' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    outputs:
      package_version: ${{ steps.vars.outputs.py_pkg_version }}
      commit_id: ${{ steps.commit_id.outputs.commit_id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: recursive

      - name: Install build-requirements
        run: |
          git config --global --add safe.directory $(pwd)
          python3 -m pip install -r build-requirements.txt

      - name: Auto Raise version
        if: ${{ inputs.deploy == 'true' }}
        run: |
          bump2version build setup.py --no-tag --no-commit --allow-dirty

      - name: Find Package details
        id: vars
        run: |
          PACKAGE_VERSION=$(cat .bumpversion.cfg | sed s/' '/''/g | grep 'current_version=' | sed s/'current_version='/''/g)
          #echo ::set-output name=py_pkg_version::$PACKAGE_VERSION
          echo "py_pkg_version=$PACKAGE_VERSION" >> $GITHUB_OUTPUT

      - name: Push auto raise version
        if: ${{ inputs.deploy == 'true' }}
        run: |
          git config --global user.name ${{ secrets.auto_commit_user }}
          git config --global user.email ${{ secrets.auto_commit_mail }}
          git add .bumpversion.cfg
          git add **__version__.py || true
          git commit -m "[skip actions] Automatic Bump of build version"

      - name: Set branch output
        id: var_branch
        run: |
          echo "Branch name is: ${GITHUB_REF#refs/heads/}"
          #echo ::set-output name=branch::${GITHUB_REF#refs/heads/}
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT

      - name: Raise App version
        if: ${{ inputs.deploy == 'true' }}
        uses: CasperWA/push-protected@v2.14.0
        with:
          token: ${{ secrets.auto_commit_pwd }}
          branch: ${{ steps.var_branch.outputs.branch }}
          unprotect_reviews: true

      - name: Commit of version
        id: commit_id
        run: |
          commit_hash=$(git log --format="%H" -n 1)
          #echo ::set-output name=commit_id::$commit_hash
          echo "commit_id=$commit_hash" >> $GITHUB_OUTPUT

  Debian-Pack:
    if: ${{ inputs.release == 'false' }}
    strategy:
      matrix:
        pack_path: ${{ fromJSON(inputs.package_paths) }}
    needs: [Raise]
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/qa/ros-buildtools-noetic:v1.1.9
      options: --user root
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    outputs:
      package_version: ${{ needs.Raise.outputs.package_version }}
      commit_id: ${{ needs.Raise.outputs.commit_id }}
    steps:
    - name: Checkout
      uses: actions/checkout@v3
      with:
        submodules: recursive

    - name: Download a single artifact
      uses: actions/download-artifact@v3
      with:
        name: packages
        path: dist

    - name: Create links for package ${{ matrix.pack_path }}
      run: |
        ln -f ${{ matrix.pack_path }}/debian/setup.py setup.py
        ln -sf ${{ matrix.pack_path }}/debian debian

    - name: Sync setup.py
      run: sed -i s/"$(cat setup.py | grep version=)"/"    version=\"${{ needs.Raise.outputs.package_version }}\","/g setup.py

    - name: Raise & Deb Pack
      run: |
        dch -b -v "${{ needs.Raise.outputs.package_version }}" "Auto created package version ${{ needs.Raise.outputs.package_version }}"
        PKG_VERSION_ANCHOR='$PKG_VERSION'
        sed -i "s/$PKG_VERSION_ANCHOR/${{ needs.Raise.outputs.package_version }}/g" ./debian/postinst
        sed -i "s/$PKG_VERSION_ANCHOR/${{ needs.Raise.outputs.package_version }}/g" ./debian/prerm
        curl -fsSL https://artifacts.cloud.mov.ai/repository/movai-applications/gpg | sudo apt-key add -
        apt update
        install_tool="apt-get -o Debug::pkgProblemResolver=yes --no-install-recommends --yes"
        mk-build-deps --install --root-cmd sudo --tool="${install_tool}" debian/control
        dpkg-buildpackage -nc -d -b -rfakeroot -us -uc -tc
        mkdir artifacts && \
        mv ../*.deb artifacts

    - name: Archive binary
      uses: actions/upload-artifact@v3
      with:
        name: artifacts
        path: artifacts/*.deb
        retention-days: 5

    - name: Remove hardlinks for package ${{ matrix.pack_path }}
      run: |
        rm -f setup.py
        rm -f debian

  Rpm-Pack:
    strategy:
      matrix:
        pack_path: ${{ fromJSON(inputs.package_paths) }}
    needs: [Raise]
    runs-on: ubuntu-20.04
    container:
      image: centos:8
    steps:
    - name: Prereq
      if: ${{ inputs.release == 'false' && inputs.rpm_build == 'true' }}
      run: |
        sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
        sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*
        yum install -y rpm-build rpmdevtools gcc make python38 git

    - name: Checkout
      if: ${{ inputs.release == 'false' && inputs.rpm_build == 'true' }}
      uses: actions/checkout@v3
      with:
        submodules: recursive

    - name: Download a single artifact
      if: ${{ inputs.release == 'false' && inputs.rpm_build == 'true' }}
      uses: actions/download-artifact@v3
      with:
        name: packages
        path: dist

    - name: Sync setup.py
      if: ${{ inputs.release == 'false' && inputs.rpm_build == 'true' }}
      run: |
        cd ${{ matrix.pack_path }}/
        if [ -f setup.py ] ; then
          sed -i s/"$(cat setup.py | grep version=)"/"    version=\"${{ needs.Raise.outputs.package_version }}\","/g setup.py
        fi

    - name: Raise & RPM Pack
      if: ${{ inputs.release == 'false' && inputs.rpm_build == 'true' }}
      run: |
        cd ${{ matrix.pack_path }}/
        if [ ! -d rpm ] ; then
          echo "No RPM dir found. skipping"
          exit 0
        fi
        RPM_BUILD_ARGS=""
        ARGS_LIST=(
        '--define "_topdir %(pwd)"'
        '--define "_builddir %{_topdir}"'
        '--define "_rpmdir %{_topdir}"'
        '--define "_sourcedir %{_topdir}"'
        '--define "_srcrpmdir %{_topdir}"'
        '--define "_rpmfilename %%{NAME}-%%{VERSION}-%%{RELEASE}.%%{ARCH}.rpm"'
        )
        for ARG in ${ARGS_LIST[@]}; do
            RPM_BUILD_ARGS="$RPM_BUILD_ARGS $ARG"
        done
        PKG_VERSION_ANCHOR='_VERSION_'
        PKG_BUILD_ID_ANCHOR='_BUILD_ID_'
        PKG_VERSION=$(echo ${{ needs.Raise.outputs.package_version }} | cut -d '-' -f 1)
        PKG_BUILD_ID=$(echo ${{ needs.Raise.outputs.package_version }} | cut -d '-' -f 2)
        sed -i "s/$PKG_VERSION_ANCHOR/$PKG_VERSION/g" ./rpm/template.spec
        sed -i "s/$PKG_BUILD_ID_ANCHOR/$PKG_BUILD_ID/g" ./rpm/template.spec

        cmd="rpmbuild $RPM_BUILD_ARGS -ba rpm/template.spec"
        eval $cmd
        # store RPM packages
        cd ..
        mkdir artifacts && \
        mv ./${{ matrix.pack_path }}/*.rpm artifacts

    - name: Archive binary
      if: ${{ inputs.release == 'false' && inputs.rpm_build == 'true' }}
      uses: actions/upload-artifact@v3
      with:
        name: artifacts
        path: artifacts/*.rpm
        retention-days: 5

  Debian-Test:
    strategy:
      matrix:
        distro: [ "20.04", "22.04" ]
    needs: [Raise, Debian-Pack]
    if: ${{ inputs.release == 'false' && inputs.install_test == 'true' }}
    runs-on: ubuntu-${{ matrix.distro }}
    timeout-minutes: 90
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: recursive

      - name: Install test requirements
        run: |
          python3 -m pip install -r build-requirements.txt

      - name: Prereq Docker
        if: ${{ inputs.install_test_docker == 'true' }}
        run: |
          sudo apt update && sudo apt install -y curl
          curl -fsSL https://get.docker.com -o get-docker.sh
          sh get-docker.sh

      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: artifacts
          path: artifacts

      - name: Install debian artifacts
        run: |
          sudo apt update
          cd artifacts/
          find ./ -name "*.deb" -not -name "*src*" -exec sudo apt install -y {} \;

      - name: Download a single artifact
        uses: actions/download-artifact@v3
        with:
          name: linting_reports
          path: ./

      - name: Run tests
        if: ${{ inputs.skip_testing != 'true' }}
        run: |
          # add current user to movai-system group and apply changes
          sudo usermod -aG movai-system $USER
          newgrp movai-system
          if [ -f tox.ini ]; then
              # run tests and generates coverage.xml
              tox
          else
              # run tests
              python3 -m pytest tests/
          fi

      - name: Create SonarCloud project and disable autoscan
        uses: MOV-AI/action-sonarcloud-proj-config@v1
        if: ${{ inputs.skip_sonar != false }}
        with:
          sonar_org: 'mov-ai'
          sonar_token: ${{ secrets.sonar_token }}

      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@v2.0.2
        if: ${{ inputs.skip_sonar != false }}
        env:
          GITHUB_TOKEN: ${{ github.token }}  # Needed to get PR information, if any
          SONAR_TOKEN: ${{ secrets.sonar_token }}
        with:
          projectBaseDir: ./
          args: >
            -Dsonar.organization=mov-ai
            -Dsonar.projectKey=${{ github.repository_owner }}_${{ github.event.repository.name }}
            -Dsonar.sources=.
            -Dsonar.scm.provider=git
            -Dsonar.qualitygate.wait=true
            -Dsonar.qualitygate.timeout=300
            -Dsonar.coverage.exclusions=tests/**
            -Dsonar.cpd.exclusions=tests/**
            -Dsonar.python.version=3
            -Dsonar.python.flake8.reportPaths=flake8-report.txt
            -Dsonar.python.pylint.reportPaths=pylint-report.txt
            -Dsonar.python.coverage.reportPaths=coverage.xml

      - name: Link to SonarCloud dashboard
        if: ${{ inputs.skip_sonar != false }}
        shell: bash
        run: |
          echo "Please check report here: https://sonarcloud.io/project/overview?id=${{ github.repository_owner }}_${{ github.event.repository.name }}"

      - name: Store logs of journalctl
        shell: bash
        if: always()
        run: |
          mkdir -p logs
          journalctl -u movai-service > ./logs/movai-service-journal-${{ matrix.distro }}.log || true

      - name: Stash logs of journalctl
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: debian_test_journal
          path: ./logs/*
          retention-days: 5


  Rpm-Test:
    needs: [Raise, Rpm-Pack]
    runs-on: ubuntu-20.04
    container:
      image: centos:8
    steps:
      - name: Prereq Docker
        if: ${{ inputs.install_test_docker == 'true' && inputs.release == 'false' && inputs.install_test == 'true' &&  inputs.rpm_build == 'true'  }}
        run: |
          sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
          sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*
          # install docker
          yum install -y python38 git curl
          curl -fsSL https://get.docker.com -o get-docker.sh
          sh get-docker.sh

      - name: Prereq Zmq
        if: ${{ inputs.install_test_zmq == 'true'  && inputs.release == 'false' && inputs.install_test == 'true' &&  inputs.rpm_build == 'true' }}
        run: |
          # add zeromq repo
          yum-config-manager --add-repo "https://download.opensuse.org/repositories/network:/messaging:/zeromq:/release-stable/RHEL_7/"
          yum install --nogpgcheck -y zeromq-devel

      - name: Download artifacts
        if: ${{ inputs.release == 'false' && inputs.install_test == 'true' &&  inputs.rpm_build == 'true' }}
        uses: actions/download-artifact@v3
        with:
          name: artifacts
          path: artifacts

      - name: Install rpm artifacts
        if: ${{ inputs.release == 'false' && inputs.install_test == 'true' &&  inputs.rpm_build == 'true' }}
        run: |
          find artifacts/ -name "*.rpm" -not -name "*src*" -print0 | xargs -0 -n1 -r yum install -y

      - name: Store logs of journalctl
        shell: bash
        if: always()
        run: |
          mkdir -p logs
          journalctl -u movai-service > ./logs/movai-service-journal-centos.log || true

      - name: Stash logs of journalctl
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: rpm_test_journal
          path: ./logs/*
          retention-days: 5

  Publish:
    needs: [Raise, Debian-Pack, Rpm-Pack, Debian-Test]
    if: ${{ inputs.deploy == 'true' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: recursive

      - name: Download a single artifact
        uses: actions/download-artifact@v3
        with:
          name: packages
          path: dist

      - name: Download a single artifact
        uses: actions/download-artifact@v3
        with:
          name: artifacts
          path: artifacts

      - name: Publish to Nexus ppa-dev
        shell: bash
        run: |
            NEXUS_ENDPOINT="artifacts.cloud.mov.ai"
            NEXUS_REPO="ppa-dev"

            for file in artifacts/*.deb
            do
              RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
              -H "Content-Type: multipart/form-data" \
              --data-binary "@$file" \
              -w '%{http_code}' \
              "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  -H "Content-Type: multipart/form-data" \
                  --data-binary "@$file" \
                  -w '%{http_code}' \
                  "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Exiting"
                exit 1
              fi
            done

      - name: Publish to Nexus ppa-testing
        shell: bash
        run: |
            NEXUS_ENDPOINT="artifacts.cloud.mov.ai"
            NEXUS_REPO="ppa-testing"

            for file in artifacts/*.deb
            do
              RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
              -H "Content-Type: multipart/form-data" \
              --data-binary "@$file" \
              -w '%{http_code}' \
              "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  -H "Content-Type: multipart/form-data" \
                  --data-binary "@$file" \
                  -w '%{http_code}' \
                  "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Exiting"
                exit 1
              fi
            done

      - name: Publish to Nexus yum-integration (new Nexus)
        if: ${{ inputs.rpm_build == 'true' }}
        shell: bash
        run: |
            NEXUS_ENDPOINT="artifacts.aws.cloud.mov.ai"
            NEXUS_REPO="yum-integration"

            cd artifacts
            for file in $(find -name "*.rpm" -not -name "*src*" -printf '%f\n')
            do
              echo "Uploading $file"
              RETURN_CODE=$(curl -X 'POST' -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                "https://$NEXUS_ENDPOINT/service/rest/v1/components?repository=$NEXUS_REPO" \
                -H 'accept: application/json' \
                -H 'Content-Type: multipart/form-data' \
                -w '%{http_code}' \
                -F 'yum.directory=system' \
                -F "yum.asset=@$file;type=application/x-rpm" \
                -F "yum.asset.filename=$file"
              )

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202|204)$ ]]; then
                echo "Failed upload $file with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -X 'POST' -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  "https://$NEXUS_ENDPOINT/service/rest/v1/components?repository=$NEXUS_REPO" \
                  -H 'accept: application/json' \
                  -H 'Content-Type: multipart/form-data' \
                  -w '%{http_code}' \
                  -F 'yum.directory=system' \
                  -F "yum.asset=@$file;type=application/x-rpm" \
                  -F "yum.asset.filename=$file"
                )
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202|204)$ ]]; then
                echo "Failed upload $file with $RETURN_CODE. Exiting"
                exit 1
              fi
            done

      - name: Create Github Release
        if: ${{ inputs.deploy == 'true' }}
        shell: bash
        run: |
          title="Release of ${{ needs.Raise.outputs.package_version }}"
          git config --global --add safe.directory $(pwd)

          gh release create -p -t "$title" \
          -n "Release notes of version ${{ needs.Raise.outputs.package_version }}" \
          --target "${{ needs.Raise.outputs.commit_id }}" \
          --generate-notes \
           ${{ needs.Raise.outputs.package_version }}


          # add all files in the artifacts folder
          assets=()
          for asset in dist/*; do
            # do nothing if folder is empty
            if [[ $asset != "dist/*" ]]; then
              gh release upload ${{ needs.Debian-Pack.outputs.package_version }} $asset
            fi
          done
          for asset in artifacts/*; do
            # do nothing if folder is empty
            if [[ $asset != "artifacts/*" ]]; then
              gh release upload ${{ needs.Debian-Pack.outputs.package_version }} $asset
            fi
          done
        env:
          GITHUB_TOKEN: ${{ secrets.gh_token }}

  Release:
    if: ${{ inputs.release == 'true' }}
    runs-on: ubuntu-20.04
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Set tag output
      id: vars
      run: echo "tag=${GITHUB_REF#refs/*/}" >> $GITHUB_OUTPUT

    - name: Fetch artifact from github release
      run: |
        git config --global --add safe.directory $(pwd)
        mkdir dist artifacts
        cd dist
        gh release download ${{ steps.vars.outputs.tag}} -p *.whl
        gh release download ${{ steps.vars.outputs.tag}} -p *.tar.gz
        cd ../artifacts
        gh release download ${{ steps.vars.outputs.tag}} -p *.deb
        gh release download ${{ steps.vars.outputs.tag}} -p *.rpm
      env:
        GITHUB_TOKEN: ${{ secrets.gh_token }}

    - name: Archive binary
      uses: actions/upload-artifact@v3
      with:
        name: packages
        path: dist/*
        retention-days: 5

    - name: Archive binary
      uses: actions/upload-artifact@v3
      with:
        name: artifacts
        path: artifacts/*.deb
        retention-days: 5

    - name: Archive binary
      uses: actions/upload-artifact@v3
      with:
        name: artifacts
        path: artifacts/*.rpm
        retention-days: 5

    - name: Publish package to prod PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: ${{ secrets.nexus_publisher_user }}
        password: ${{ secrets.nexus_publisher_password }}
        repository-url: https://artifacts.cloud.mov.ai/repository/${{ inputs.prod_publish_pypi }}/

    - name: Publish to Nexus
      shell: bash
      run: |
            NEXUS_REPO="${{ matrix.publish_repo }}"
            if [ "$NEXUS_REPO" != "ppa-public" ]; then
              NEXUS_ENDPOINT="artifacts.cloud.mov.ai"
            else
              NEXUS_ENDPOINT="artifacts.aws.cloud.mov.ai"
            fi

            for file in artifacts/*.deb
            do
              RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
              -H "Content-Type: multipart/form-data" \
              --data-binary "@$file" \
              -w '%{http_code}' \
              "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")

              #retry
              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Retrying"

                RETURN_CODE=$(curl -u "${{ secrets.nexus_publisher_user }}:${{ secrets.nexus_publisher_password }}" \
                  -H "Content-Type: multipart/form-data" \
                  --data-binary "@$file" \
                  -w '%{http_code}' \
                  "https://$NEXUS_ENDPOINT/repository/$NEXUS_REPO/")
              fi

              if [[ ! "$RETURN_CODE" =~ ^(200|201|202)$ ]]; then
                echo "Failed upload with $RETURN_CODE. Exiting"
                exit 1
              fi

            done
